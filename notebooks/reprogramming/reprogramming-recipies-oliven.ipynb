{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be52c6f-6647-4d93-b0bf-3e05e87917e1",
   "metadata": {},
   "source": [
    "# Reprogramming Recepies\n",
    "\n",
    "Auth: Nat Oliven, Joshua Pickard\n",
    "\n",
    "Date: August 26, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999b35ad-3c67-4023-bfcd-0da39d281c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1edb3a-5d7c-4230-a2cb-5ec790935dd3",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa696c58-66b2-4eba-a1b1-b578eff3ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a489b88-60e1-4387-8d03-20c129931da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93426a-3ff0-44e1-8b41-5d5e89d56666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270230bf-4742-48c8-90ab-0ba4ded0513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['TFs'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e2060-2c16-4f3b-9f64-cf1807778708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'P53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16'],\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "    # this one didn't show up\n",
    "    'LXH3': ['M2-LHX3', 'M2LHX3', 'CPHD3', 'LIM3'],\n",
    "    'NGN2': ['NEUROG2', 'BHLHA8', 'MATH4A', 'Math4a', 'ATOH4', 'Ngn-2', 'BHLHA8', 'Atoh4', 'NGN-2'],\n",
    "    'LMX1A': ['LMX1.1', 'LMX1', 'LMX-1.', 'DFNA7'],\n",
    "    # NF-Kb had  a strange genecards lookup\n",
    "    'NF-ΚB': ['NFkb1', 'NFKB1'], \n",
    "    'L-MYC': ['MYCL', 'LMYC', 'BHLHe38', 'MYCL1', 'BHLHE38'],\n",
    "    'BRN2': ['POU3F2', 'BRN2', 'OCT7', 'POUF3', 'OTF7', 'Brain-2', 'OTF-7', 'Brn-2', 'Oct-7', 'N-Oct3'], \n",
    "    'NURR1': ['NR4A2', 'TINUR', 'NOT', 'HZF3', 'NURR1', 'RNR1', 'IDLDP'],\n",
    "    'SOX2': ['SRY-Box 2', 'MCOPS3', 'ANOP3'],\n",
    "    'NEUROD': ['NEUROD1', 'BHLHa3', 'BETA2', 'BHF-1', 'MODY6', 'NeuroD1', 'BHLHA3', 'T2D'],\n",
    "    'C-MYC': ['MYC', 'C-MYC', 'MYCC', 'MRTL', 'BHLHE39'],\n",
    "    # AP-2A had  a strange genecards lookup\n",
    "    'AP-2A': [' '],\n",
    "    'PAX6': ['D11S812E', 'WAGR', 'AN2', 'AN', 'AN1', 'ASGD5', 'FVH1', 'MGDA'],\n",
    "    'OSTERIX': ['SP7', 'OSX', 'OI11', 'OI12'],\n",
    "    # OCT6 had a strange genecards lookup\n",
    "    'OCT6': ['POU3F1', 'SCIP', 'OTF6', 'OTF-6'],\n",
    "   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed97378-5da6-46b7-9b51-d1b8fca15442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2881f1-9966-4946-a2c4-d27fb6de066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5db023-1ae7-46cf-a4d8-7a9eaf5b193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba1127-ee3c-478f-8298-4a738d540bc6",
   "metadata": {},
   "source": [
    "# Day 4: Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c0cbf-311c-4de6-9e83-8dae191d7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05aa9b-e46f-4a68-a047-704b9fb4effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['TFs'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d64c66-8ea7-4ea6-928e-b907f456735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'p53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16']\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932fa31-967f-4f7f-ab6b-845791e191c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0183d92-2ee0-4b6f-a711-9cdc55a23260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e04100-5836-4bb5-985b-252c739d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above list is small enough that I can manually check it.\n",
    "\n",
    "# Things to remove from word_list:\n",
    "not_genes = ['Variant', 'Large',  '(ETS', '2)', 'Knockdown', ]\n",
    "\n",
    "# Valid genes to replace/rename in word_list:\n",
    "genes_to_translate = ['LMX1A;', #'P53']\n",
    "translated_names = ['LMX1A',]\n",
    "\n",
    "# These ones might have appeared as multiple entries, etc. b/c of spacing. easiest way was to delete and add back\n",
    "genes_to_add = ['ETS2',]\n",
    "\n",
    "# replace then subtract and add. [--------------]\n",
    "new_word_list = set(word_list) - set(not_genes)\n",
    "\n",
    "# Running the function one more time to check:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b55c4-7e15-47c1-8173-4859a1a32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Renamed med_nonz to max_exp to be more accurate. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1607b7d-0394-4092-b3d7-1f5337304ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a083ac-8ec8-4b5e-8084-3299bf915df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d543ea4-8e81-4a18-8a6a-9d58cca3794f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Day 4: Copied From Josh's Notebook\n",
    "\n",
    "**Focus:** check out Nats code (debug a bit) and create a few perturbations\n",
    "- changes made to NO's code:\n",
    "    1. iterate_perturb_counts: changes the order of the arguments to `adata, tf_list, scalar_list`\n",
    "    2. perturb_counts: changes the order of the arguments to `adata, tf_list, scalar_list`\n",
    "    3. perturb_counts: there was an issue with the use of `[: np.newaxis]` with respect to `max_exp`, which is a `coo_matrix` (special type of sparse matrix). Code was modified to address an issue being thrown here.\n",
    "- new function:\n",
    "    1. validateTFs(TFs, adata): this checks if all the transcription factors are present in the adata\n",
    "- pertrubation driver (`Perform Perturbations and Create new files`):\n",
    "    1. loads Fibroblast data from Tabula Sapiens\n",
    "    2. loads `.csv` file of known reprogrmaming protocols\n",
    "    3. for each set of TFs that are validated by `validateTFs`:\n",
    "        1. use `iterate_perturb_counts` to generate perturbations with scalars `[0.5, 0.75, 1]`\n",
    "        2. concatenate the dataframes to make a single dataframe\n",
    "        3. save metadata from reprogramming protocol (i.e. PMID, source/targets, etc.)\n",
    "        4. save the new anndata as a `.h5ad` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7570a-143e-42ce-9da0-092a30f2a5de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nat's Code with some modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b62fc-2de4-4c72-989b-dd5b2c2447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e22ec-6676-4879-94a7-7ecdf360fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_perturb_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "    \n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5645f9-2865-4256-9a67-16714be224ba",
   "metadata": {},
   "source": [
    "## New code to validate lists of TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458b5b2-728b-4868-91ac-dd439523a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateTFs(TFs, adata):\n",
    "    adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "    for TF in TFs:\n",
    "        if TF not in adata_gene_list:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf8a3e-cbf6-4a03-810d-52d07b426076",
   "metadata": {},
   "source": [
    "## Load data and perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da050-9ac3-4a40-82fe-ff3c9f125689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/first_5_recepies_8_29_2024.csv')\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/jpic/\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754f880-759d-4ceb-ad5e-c7aec8535f99",
   "metadata": {},
   "source": [
    "## Perform Perturbations and Create new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf265d-6a26-476b-826a-08997f1c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['TFs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c916f-8cca-4155-a81b-318d253ca6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/one-shot/perturbed\"\n",
    "scalars = [0.5, 0.75, 1.001]\n",
    "for i in range(len(df['TFs'])):\n",
    "    val = df['TFs'].iloc[i]\n",
    "    val = val.replace(',',' ')\n",
    "    val = val.replace(';',' ')\n",
    "    val = val.replace(':',' ')\n",
    "    TFs = val.split(' ')\n",
    "    if validateTFs(TFs, adata):\n",
    "        print(TFs)\n",
    "        adataDict = iterate_perturb_counts(adata, TFs, scalars)\n",
    "\n",
    "        # Concatenate all AnnData objects along the observations axis\n",
    "        concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "        # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "        concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "        concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "        concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "        concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "        concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "        concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "        concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "        \n",
    "        # Join the TFs list into a string for the filename\n",
    "        TFs_str = \"_\".join(TFs)\n",
    "        \n",
    "        # Generate the file path for saving\n",
    "        file_name = f\"{TFs_str}.h5ad\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "        \n",
    "        # Save the concatenated AnnData object to the file\n",
    "        concatenated_adata.write_h5ad(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3a04e-5927-424b-9a17-fb698e0d5d4b",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae743d0-4445-45da-aa67-60dbfd13aa6e",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca734bb-76c1-453b-b0bb-e2caaff6be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c1301-ecaa-40f0-bcc4-aba1e08e04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['TFs'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62011aea-3548-4942-847a-d17616055966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'p53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16']\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f439e6-738c-4cba-8067-fc8a28af8a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1df6ef-73f6-4d86-8dfe-335d4a067b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00a2c8-771e-463a-bdbb-3668d31b6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above list is small enough that I can manually check it.\n",
    "\n",
    "# Things to remove from word_list:\n",
    "not_genes = ['Variant', 'Large',  '(ETS', '2)', 'Knockdown', ]\n",
    "\n",
    "# Valid genes to replace/rename in word_list:\n",
    "genes_to_translate = ['LMX1A;', #'P53']\n",
    "translated_names = ['LMX1A',]\n",
    "\n",
    "# These ones might have appeared as multiple entries, etc. b/c of spacing. easiest way was to delete and add back\n",
    "genes_to_add = ['ETS2',]\n",
    "\n",
    "# replace then subtract and add. [--------------]\n",
    "new_word_list = set(word_list) - set(not_genes)\n",
    "\n",
    "# Running the function one more time to check:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bed245-f122-47cd-bc76-814e682c23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Renamed med_nonz to max_exp to be more accurate. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee7615-c3ae-4b05-a473-e3274728c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb06cf-f71b-4c2c-b8a2-9d7b81346258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82877-b10f-48f4-894a-ebdf8117d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want each recipe (returned as a dictionary of anndata objects, one adata object for each scalar)\n",
    "def save_perturb_to_turbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0a638-b15e-4589-94d6-0275ada43a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing on one of the tf lists from the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2d9cc-78c2-4d3c-a3c2-b0710a27000c",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb10707-df05-4e7d-a9a4-bd301ab5cd69",
   "metadata": {},
   "source": [
    "## Perturbation Model Discussion\n",
    "\n",
    "E.V. = expression values\n",
    "\n",
    "Possible algorithm:\n",
    "```\n",
    "1. find highest E.V.  for a single cell\n",
    "2. find expression value of TFs being modified\n",
    "3. have a value k for the number of different concentrations we want to test\n",
    "4. choose k different amounts to increase the TFs from there measured E.V. to the 150% maximum E.V.\n",
    "   - make an arbitray choice and code it up\n",
    "```\n",
    "\n",
    "**A reasonable person could write this 10s of different ways**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206882c6-cec6-4a8b-9605-bfdc8b058823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# median nonzero value of each row\n",
    "# the w stands for working. I just dont want to screw up the original.\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_w\n",
    "# def median_nonzero(col):\n",
    "#     nonzero_vals = col[col != 0]  # Extract nonzero values\n",
    "#     if len(nonzero_vals) == 0:    # If no nonzero values, return NaN\n",
    "#         return np.nan\n",
    "#     return np.median(nonzero_vals)\n",
    "\n",
    "# # Apply the function to each column and store the results\n",
    "# med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=adata_w.X)\n",
    "# adata_w.var['med_nonz'] = med_nonz\n",
    "# adata_w.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d3635-dfd9-4412-9d95-cfcbfdf0fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X = adata_w.X.toarray() if not isinstance(adata_w.X, np.ndarray) else adata_w.X\n",
    "\n",
    "def median_nonzero(col):\n",
    "    nonzero_vals = col[col != 0] \n",
    "    return np.median(nonzero_vals) if len(nonzero_vals) > 0 else 0\n",
    "\n",
    "#perform and save results of fn\n",
    "med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=X)\n",
    "adata_w.var['med_nonz'] = med_nonz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06553f13-9b94-4a5f-9039-bcf183b14ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_w.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2c287-8651-4280-b369-60bcae264beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing what it looks like before tf_list changes the first 3 rows\n",
    "# Convert to dense if it's sparse and display the first five rows\n",
    "import numpy as np\n",
    "\n",
    "# Convert to a dense array if necessary\n",
    "dense_X = adata_w.X.toarray() if not isinstance(adata_w.X, np.ndarray) else adata_w.X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621349c1-2e81-4842-b701-ef86075bebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem, scaling by a factor of the max expressed gene in that cell means that you could be scaling by different genes for each cell,\n",
    "# when the cells are all of the same type. for each get the median nonzero expression\n",
    "\n",
    "# for testing purposes: v\n",
    "tf_list = ['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "tf = 'DDX11L1'\n",
    "# for testing purposes: ^\n",
    "\n",
    "#mask = adata_w.obs_names.isin(tf_list)\n",
    "mask = np.where(adata_w.var['gene_symbol'] == tf)[0]\n",
    "adata_w.X[mask, :] = adata_w.X[mask, :] * adata_w.var['med_nonz'].values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff775d-3988-4580-b7b4-c348ba958f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "(adata_w.X[mask, :] - adata.X[mask, :]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea8504-7206-427a-b4ad-5d0a58f8fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_w.X[mask, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84ecb9-b34c-4db6-82e2-b5d99fa1a35e",
   "metadata": {},
   "source": [
    "### Scaling by median nonzero entry of each gene across all cells (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a102f-4053-420a-9d04-b21410d9853d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "# FILE = \"TS_epithelial.h5ad\"\n",
    "# adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "# #tf = 'DDX11L1'\n",
    "# tf_list =['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "\n",
    "# def median_nonzero(col):\n",
    "#     nonzero_vals = col[col != 0] \n",
    "#     return np.median(nonzero_vals) if len(nonzero_vals) > 0 else 0\n",
    "\n",
    "# # requires scalar is a scalar\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # compute nonzero median expression of each gene across cells, save to var\n",
    "#     med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=adata.X)\n",
    "#     adata.var['med_nonz'] = med_nonz\n",
    "\n",
    "#     # filter by desired tf(s), and apply the nonzero_median scaling operation to only these  \n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[mask, :] = adata.X[mask, :] * adata.var['med_nonz'].values * scalar\n",
    "#     return adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1fc75-0e49-4800-9c33-d147e4bac06d",
   "metadata": {},
   "source": [
    "### Scaling by max gene expression within each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebbee6-3805-417a-9425-e99f2b8b35db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# old version with (I believe) improper mask that was being applied to rows and not columns\n",
    "\n",
    "# import numpy as np\n",
    "# DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "# FILE = \"TS_epithelial.h5ad\"\n",
    "# adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "# #tf = 'DDX11L1'\n",
    "# tf_list =['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "\n",
    "\n",
    "# # requires scalar is a scalar\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # compute nonzero median expression of each gene across cells, save to var\n",
    "#     med_nonz = med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "\n",
    "#     # filter by desired tf(s), and apply the nonzero_median scaling operation to only these  \n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[mask, :] = adata.X[mask, :] * adata.obs['med_nonz'].values * scalar\n",
    "#     return adata\n",
    "\n",
    "# old version without extra obs and var rows telling what was scaled and by how much\n",
    "\n",
    "\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # Compute maximum expression level of each cell and save it to obs\n",
    "#     med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "    \n",
    "#     # apply operation only to genes in tf_list\n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[:, mask] = adata.X[:, mask] * adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# version before gpt optimized\n",
    "\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # Compute maximum expression level of each cell and save it to obs\n",
    "#     med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "    \n",
    "#     # Add a new obs column called 'scalar' containing the scalar value for each row\n",
    "#     adata.obs['scalar'] = scalar\n",
    "    \n",
    "#     # Create a mask for genes in tf_list\n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     # Apply the scaling operation to the specified genes\n",
    "#     adata.X[:, mask] = adata.X[:, mask] * adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "    \n",
    "#     # Add a new var column called 'scaled' with True for genes in tf_list and False otherwise\n",
    "#     adata.var['scaled'] = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "#     # Add a new var column 'scaled_by'\n",
    "#     adata.var['scaled_by'] = 1\n",
    "#     # Set scaling factor for genes in tf_list\n",
    "\n",
    "#     ############I asked gpt to do this line and am unsure if it is correct. checking now.\n",
    "#     adata.var.loc[adata.var['scaled'], 'scaled_by'] = adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "#     ###############\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# loop version before gpt optimized\n",
    "\n",
    "# # requires that within each perturbation, all of the transcription factors in tf_list are scaled by the same amount, that is, (scalar * \"max gene expression in that cell\")\n",
    "# # requires adata is cells x genes\n",
    "\n",
    "# import anndata\n",
    "\n",
    "# def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "#     adata_dict = {}\n",
    "    \n",
    "#     for scalar in scalar_list:\n",
    "#         adata_temp = adata.copy()\n",
    "#         perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "#         adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "#     return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99114ac8-38af-488b-8856-acc26632b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    med_nonz = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Apply the scaling operation to the specified genes\n",
    "    adata.X[:, gene_mask] *= med_nonz[:, np.newaxis] * scalar\n",
    "    \n",
    "    # Add/Update 'scaled' column in var\n",
    "    adata.var['scaled'] = gene_mask\n",
    "    \n",
    "    # Add/Update 'scaled_by' column in var\n",
    "    adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "    adata.var.loc[gene_mask, 'scaled_by'] = med_nonz[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a79c50-3dbb-4d6f-8723-e6f967f41893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f0a9c-18e0-4d3a-8efd-7993accb1048",
   "metadata": {},
   "source": [
    "## Visualize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8542f13-3c5c-4130-9766-0d0a9ce55e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6474b05-224f-4677-902e-5b4962a4bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a5de2-be21-489c-8184-b90f010b06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010c3f2-3294-4f18-bcad-8a9b3abf9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f83ed-4955-4962-a629-f003027303e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.max(axis=1) # what is the value of the highest expressed gene for each cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210614f-0e87-4a8a-b1c5-1cc95c7380ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = 'DDX11L1'\n",
    "index = np.where(adata.var['gene_symbol'] == TF)[0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3d5ad-f2f0-446d-83f3-c63179d369c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['gene_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45904679-08f7-4ec7-b746-4017140120c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa3850-58e1-41b4-9b2a-60db4bea28b1",
   "metadata": {},
   "source": [
    "## Build driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563c2da-5366-4738-a33b-2bfe1e881eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def main(job_number, parameter_file):\n",
    "    \"\"\"\n",
    "    This is the main function for the array job to perform the reprogramming experiment. job_number is a single parameter\n",
    "    that will be used to look up in a parameter table which model, reprogramming recipe, and other information relevant\n",
    "    to the test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine embedding parameters and recipie\n",
    "    df_embedding_parameters = pd.read_csv(parameter_file)\n",
    "    TFs    = df_embedding_parameters['TFs'].values[job_number]\n",
    "    model  = df_embedding_parameters['model'].values[job_number]\n",
    "    source = df_embedding_parameters['source'].values[job_number]\n",
    "    target = df_embedding_parameters['target'].values[job_number]\n",
    "\n",
    "    # Load the source data\n",
    "    adata = \n",
    "\n",
    "    # Perturb the data\n",
    "    perturbed_adata = perturbation_model(adata, TFs)\n",
    "\n",
    "    # Generate embeddings\n",
    "    if model == 'geneformer':\n",
    "        adata_embedded = embed_geneformer([source_adata, perturbed_adata, target_adata])\n",
    "    elif model == 'tGPT':\n",
    "        adata_embedded = embed_tGPT([source_adata, perturbed_adata, target_adata])\n",
    "    elif model == 'scGTP':\n",
    "        adata_embedded = embed_scGTP([source_adata, perturbed_adata, target_adata])\n",
    "\n",
    "    # Save the results to a file\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f3c98-3474-4971-a559-f0a294dba782",
   "metadata": {},
   "source": [
    "## Build parameter dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f04aa-ab4c-44fc-86e0-f69d7f21451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_parameters = {\n",
    "    'source': [],\n",
    "    'target': [],\n",
    "    'TFs'   : [],\n",
    "    'model' : []\n",
    "}\n",
    "models = ['geneformer', 'tGPT', 'scGTP']\n",
    "\n",
    "df = pd.read_csv('data/first_5_recepies_8_29_2024.csv')\n",
    "\n",
    "for i in range(5):\n",
    "    TFs = df['TFs'].values[i].split()\n",
    "    source = df['Source'].values[i]\n",
    "    target = df['Target'].values[i]\n",
    "    for model in models:\n",
    "        embedding_parameters['TFs'].append(TFs)\n",
    "        embedding_parameters['source'].append(source)\n",
    "        embedding_parameters['target'].append(source)\n",
    "        embedding_parameters['model'].append(model)\n",
    "\n",
    "df_embedding_parameters = pd.DataFrame(embedding_parameters)\n",
    "\n",
    "df_embedding_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad22cdb-f1ac-48b6-8053-b69d91309c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02020-7129-4182-9bef-6535490e26a9",
   "metadata": {},
   "source": [
    "# Day 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18574c-9e46-4c1d-9b77-b4f888ae0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a5d48-99dc-4880-809d-519448cbfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known reprogramming regiems\n",
    "df = pd.read_csv('data/known-regiems-T1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457114f-57d5-45e9-ad8d-ecaa06a76d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique transcription factors\n",
    "TFs = []\n",
    "for regime in df['TFs'].unique():\n",
    "    TFs += regime.replace(',', '').split()\n",
    "TFs = list(set(TFs))\n",
    "print(f\"{len(TFs)=}\")\n",
    "TFs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
