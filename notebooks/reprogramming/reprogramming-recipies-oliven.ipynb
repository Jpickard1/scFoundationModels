{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be52c6f-6647-4d93-b0bf-3e05e87917e1",
   "metadata": {},
   "source": [
    "# Reprogramming Recepies\n",
    "\n",
    "Auth: Nat Oliven, Joshua Pickard\n",
    "\n",
    "Date: August 26, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999b35ad-3c67-4023-bfcd-0da39d281c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import anndata as ad\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a8e5a-e0dd-4829-8a27-d1ae0f154578",
   "metadata": {},
   "source": [
    "# Day 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a328cab-5d16-45c4-b196-a83cb7fc35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" It's clear from plotting that there are bugs in day 14's code. I am going to take the kmeans code and load in a toy dataset\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041e1be2-7d12-4b82-9431-616bad163dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51dbbc14-b1a9-414f-b1b2-a182aac36cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia: 78.85144142614602\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "X = iris.frame.drop(columns='target')  # Features only\n",
    "\n",
    "# Fit K-means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Access inertia\n",
    "inertia = kmeans.inertia_\n",
    "print(f\"Inertia: {inertia}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf67e0-0d8c-4b68-a40a-4f6385b0fd2c",
   "metadata": {},
   "source": [
    "# Day 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86de887-d95b-49ef-a4a2-b4ffb87d6e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The goal for today is to take the silhouette scores out of each file (are they still in uns or was that changed to make the code run?) and consolidate them to one place so that they can be plotted.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We now appear to have at least some of the embeddings of the initial fibroblasts for every n value (wanted to do 5 runs for each but array job timed out so we have around 3.\"\"\"\n",
    "\"\"\"The goal for today is to take the silhouette scores out of each file (are they still in uns or was that changed to make the code run?) and consolidate them to one place so that they can be plotted.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf01963d-af7e-4fd1-9166-9a88f55f81eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>ensemblid</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>means</th>\n",
       "      <th>dispersions</th>\n",
       "      <th>dispersions_norm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DDX11L1</th>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>False</td>\n",
       "      <td>6.398244e-05</td>\n",
       "      <td>0.835044</td>\n",
       "      <td>-0.573947</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.005574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASH7P</th>\n",
       "      <td>WASH7P</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>False</td>\n",
       "      <td>2.274395e-03</td>\n",
       "      <td>2.442280</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.031731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIR6859-1</th>\n",
       "      <td>MIR6859-1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>False</td>\n",
       "      <td>6.175251e-05</td>\n",
       "      <td>1.295335</td>\n",
       "      <td>-0.256874</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIR1302-2HG</th>\n",
       "      <td>MIR1302-2HG</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>False</td>\n",
       "      <td>1.372886e-04</td>\n",
       "      <td>2.656352</td>\n",
       "      <td>0.680668</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.008041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIR1302-2</th>\n",
       "      <td>MIR1302-2</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>ENSG00000284332</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gene_symbol     feature_type        ensemblid  highly_variable  \\\n",
       "DDX11L1          DDX11L1  Gene Expression  ENSG00000223972            False   \n",
       "WASH7P            WASH7P  Gene Expression  ENSG00000227232            False   \n",
       "MIR6859-1      MIR6859-1  Gene Expression  ENSG00000278267            False   \n",
       "MIR1302-2HG  MIR1302-2HG  Gene Expression  ENSG00000243485            False   \n",
       "MIR1302-2      MIR1302-2  Gene Expression  ENSG00000284332            False   \n",
       "\n",
       "                    means  dispersions  dispersions_norm      mean       std  \n",
       "DDX11L1      6.398244e-05     0.835044         -0.573947  0.000039  0.005574  \n",
       "WASH7P       2.274395e-03     2.442280          0.533203  0.001080  0.031731  \n",
       "MIR6859-1    6.175251e-05     1.295335         -0.256874  0.000033  0.005634  \n",
       "MIR1302-2HG  1.372886e-04     2.656352          0.680668  0.000048  0.008041  \n",
       "MIR1302-2    1.000000e-12          NaN          0.000000  0.000000  1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('data/HumanTFs_v_1.01.csv') # now comes from csv file and not straight from web\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "\n",
    "adata.var['ensemblid'] = adata.var['ensemblid'].str.split('.').str[0] # JP Add this line\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde58112-e36d-4be9-acc4-23d1b074c219",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'kmeans_82_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_fib_adata \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mread_h5ad(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/fibroblast_typing_9_20_n/output_kmeans/ts_fb_86_3_clusters.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_fib_adata\u001b[38;5;241m.\u001b[39muns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilhouette_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans_82_3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kmeans_82_3'"
     ]
    }
   ],
   "source": [
    "test_fib_adata = sp.read_h5ad(\"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/fibroblast_typing_9_20_n/output_kmeans/ts_fb_86_3_clusters.h5ad\")\n",
    "test_fib_adata.uns[\"silhouette_scores\"][\"kmeans_82_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a9766-f90b-43c1-9d87-41d218ef1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in the file kmeans_ 77_1\n",
      "Read in the file kmeans_ 84_2\n",
      "Read in the file kmeans_ 62_1\n",
      "Read in the file kmeans_ 58_1\n",
      "Read in the file kmeans_ 33_2\n",
      "Read in the file kmeans_ 35_4\n",
      "Read in the file kmeans_ 78_2\n",
      "Read in the file kmeans_ 66_2\n",
      "Read in the file kmeans_ 20_2\n"
     ]
    }
   ],
   "source": [
    "# this code works and condenses the sillhouette scores into one dataframe\n",
    "\n",
    "# import os\n",
    "# import anndata as ad\n",
    "\n",
    "# # Directory containing the h5ad files\n",
    "# directory = '/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/fibroblast_typing_9_20_n/output_kmeans/'\n",
    "\n",
    "# # Combined dictionary to store silhouette scores\n",
    "# combined_silhouette_scores = {}\n",
    "\n",
    "# # Loop through each file in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.h5ad'):\n",
    "#         # Parse n_clusters and run from the filename\n",
    "#         parts = filename.split('_')\n",
    "#         n_clusters = parts[2]  # 33 in \"ts_fb_33_3_clusters.h5ad\"\n",
    "#         run = parts[3]  # 3 in \"ts_fb_33_3_clusters.h5ad\"\n",
    "\n",
    "#         # Load the h5ad file\n",
    "#         file_path = os.path.join(directory, filename)\n",
    "#         adata = ad.read_h5ad(file_path)\n",
    "#         print(\"Read in the file kmeans_ \" + str(n_clusters) + \"_\" + str(run))\n",
    "\n",
    "#         # Extract silhouette score dictionary\n",
    "#         key = f'kmeans_{n_clusters}_{run}'\n",
    "#         score = adata.uns['silhouette_scores'].get(key)\n",
    "\n",
    "#         # Add to combined dictionary\n",
    "#         if score is not None:\n",
    "#             combined_silhouette_scores[key] = score\n",
    "\n",
    "# # Now `combined_silhouette_scores` contains the combined dictionary from all files\n",
    "# print(combined_silhouette_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2846900a-f733-43ff-91b1-bf8b96366050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in the file kmeans_77_1\n",
      "Read in the file kmeans_84_2\n",
      "Read in the file kmeans_62_1\n",
      "Read in the file kmeans_58_1\n",
      "Read in the file kmeans_33_2\n",
      "Read in the file kmeans_35_4\n",
      "Read in the file kmeans_78_2\n",
      "Read in the file kmeans_66_2\n",
      "Read in the file kmeans_20_2\n",
      "Read in the file kmeans_92_1\n",
      "Read in the file kmeans_14_1\n",
      "Read in the file kmeans_53_1\n",
      "Read in the file kmeans_21_2\n",
      "Read in the file kmeans_46_3\n",
      "Read in the file kmeans_56_1\n",
      "Read in the file kmeans_47_3\n",
      "Read in the file kmeans_9_2\n",
      "Read in the file kmeans_21_3\n",
      "Read in the file kmeans_83_1\n",
      "Read in the file kmeans_36_4\n",
      "Read in the file kmeans_14_3\n",
      "Read in the file kmeans_82_3\n",
      "Read in the file kmeans_27_2\n",
      "Read in the file kmeans_65_1\n",
      "Read in the file kmeans_63_1\n",
      "Read in the file kmeans_99_2\n",
      "Read in the file kmeans_11_2\n",
      "Read in the file kmeans_28_1\n",
      "Read in the file kmeans_67_1\n",
      "Read in the file kmeans_94_3\n",
      "Read in the file kmeans_20_4\n",
      "Read in the file kmeans_79_2\n",
      "Read in the file kmeans_50_1\n",
      "Read in the file kmeans_64_1\n",
      "Read in the file kmeans_58_2\n",
      "Read in the file kmeans_5_2\n",
      "Read in the file kmeans_86_2\n",
      "Read in the file kmeans_9_4\n",
      "Read in the file kmeans_62_2\n",
      "Read in the file kmeans_92_2\n",
      "Read in the file kmeans_71_2\n",
      "Read in the file kmeans_15_2\n",
      "Read in the file kmeans_73_2\n",
      "Read in the file kmeans_34_2\n",
      "Read in the file kmeans_98_1\n",
      "Read in the file kmeans_30_1\n",
      "Read in the file kmeans_67_3\n",
      "Read in the file kmeans_15_4\n",
      "Read in the file kmeans_85_1\n",
      "Read in the file kmeans_60_1\n",
      "Read in the file kmeans_83_3\n",
      "Read in the file kmeans_88_1\n",
      "Read in the file kmeans_66_1\n",
      "Read in the file kmeans_82_2\n",
      "Read in the file kmeans_47_1\n",
      "Read in the file kmeans_75_2\n",
      "Read in the file kmeans_7_1\n",
      "Read in the file kmeans_74_1\n",
      "Read in the file kmeans_80_1\n",
      "Read in the file kmeans_47_4\n",
      "Read in the file kmeans_19_4\n",
      "Read in the file kmeans_5_4\n",
      "Read in the file kmeans_37_2\n",
      "Read in the file kmeans_10_1\n",
      "Read in the file kmeans_31_3\n",
      "Read in the file kmeans_93_1\n",
      "Read in the file kmeans_8_4\n",
      "Read in the file kmeans_51_2\n",
      "Read in the file kmeans_99_3\n",
      "Read in the file kmeans_78_3\n",
      "Read in the file kmeans_50_4\n",
      "Read in the file kmeans_38_4\n",
      "Read in the file kmeans_41_3\n",
      "Read in the file kmeans_87_3\n",
      "Read in the file kmeans_7_2\n",
      "Read in the file kmeans_96_1\n",
      "Read in the file kmeans_12_2\n",
      "Read in the file kmeans_30_4\n",
      "Read in the file kmeans_20_1\n",
      "Read in the file kmeans_8_1\n",
      "Read in the file kmeans_83_2\n",
      "Read in the file kmeans_12_3\n",
      "Read in the file kmeans_70_3\n",
      "Read in the file kmeans_22_4\n",
      "Read in the file kmeans_28_3\n",
      "Read in the file kmeans_26_2\n",
      "Read in the file kmeans_88_2\n",
      "Read in the file kmeans_51_4\n",
      "Read in the file kmeans_41_4\n",
      "Read in the file kmeans_95_1\n",
      "Read in the file kmeans_14_4\n",
      "Read in the file kmeans_85_2\n",
      "Read in the file kmeans_44_2\n",
      "Read in the file kmeans_84_3\n",
      "Read in the file kmeans_57_1\n",
      "Read in the file kmeans_39_1\n",
      "Read in the file kmeans_25_1\n",
      "Read in the file kmeans_62_4\n",
      "Read in the file kmeans_49_3\n",
      "Read in the file kmeans_37_1\n",
      "Read in the file kmeans_63_3\n",
      "Read in the file kmeans_48_3\n",
      "Read in the file kmeans_54_4\n",
      "Read in the file kmeans_57_2\n",
      "Read in the file kmeans_6_1\n",
      "Read in the file kmeans_77_3\n",
      "Read in the file kmeans_22_2\n",
      "Read in the file kmeans_81_1\n",
      "Read in the file kmeans_75_1\n",
      "Read in the file kmeans_22_1\n",
      "Read in the file kmeans_42_2\n",
      "Read in the file kmeans_15_3\n",
      "Read in the file kmeans_44_4\n",
      "Read in the file kmeans_58_3\n",
      "Read in the file kmeans_10_4\n",
      "Read in the file kmeans_17_3\n",
      "Read in the file kmeans_86_1\n",
      "Read in the file kmeans_55_1\n",
      "Read in the file kmeans_19_3\n",
      "Read in the file kmeans_24_3\n",
      "Read in the file kmeans_79_3\n",
      "Read in the file kmeans_16_1\n",
      "Read in the file kmeans_90_1\n",
      "Read in the file kmeans_93_3\n",
      "Read in the file kmeans_53_3\n",
      "Read in the file kmeans_89_1\n",
      "Read in the file kmeans_55_2\n",
      "Read in the file kmeans_63_2\n",
      "Read in the file kmeans_76_3\n",
      "Read in the file kmeans_23_1\n",
      "Read in the file kmeans_45_3\n",
      "Read in the file kmeans_90_3\n",
      "Read in the file kmeans_25_3\n",
      "Read in the file kmeans_39_2\n",
      "Read in the file kmeans_27_3\n",
      "Read in the file kmeans_6_4\n",
      "Read in the file kmeans_74_3\n",
      "Read in the file kmeans_96_3\n",
      "Read in the file kmeans_89_2\n",
      "Read in the file kmeans_61_2\n",
      "Read in the file kmeans_57_3\n",
      "Read in the file kmeans_72_1\n",
      "Read in the file kmeans_20_3\n",
      "Read in the file kmeans_26_1\n",
      "Read in the file kmeans_71_1\n",
      "Read in the file kmeans_15_1\n",
      "Read in the file kmeans_59_3\n",
      "Read in the file kmeans_18_1\n",
      "Read in the file kmeans_64_2\n",
      "Read in the file kmeans_71_3\n",
      "Read in the file kmeans_5_3\n",
      "Read in the file kmeans_51_3\n",
      "Read in the file kmeans_93_2\n",
      "Read in the file kmeans_50_2\n",
      "Read in the file kmeans_5_1\n",
      "Read in the file kmeans_79_1\n",
      "Read in the file kmeans_24_1\n",
      "Read in the file kmeans_41_2\n",
      "Read in the file kmeans_70_1\n",
      "Read in the file kmeans_90_2\n",
      "Read in the file kmeans_13_4\n",
      "Read in the file kmeans_47_2\n",
      "Read in the file kmeans_16_3\n",
      "Read in the file kmeans_49_2\n",
      "Read in the file kmeans_9_1\n",
      "Read in the file kmeans_23_4\n",
      "Read in the file kmeans_68_1\n",
      "Read in the file kmeans_45_1\n",
      "Read in the file kmeans_73_3\n",
      "Read in the file kmeans_31_2\n",
      "Read in the file kmeans_14_2\n",
      "Read in the file kmeans_16_4\n",
      "Read in the file kmeans_32_4\n",
      "Read in the file kmeans_8_3\n",
      "Read in the file kmeans_44_1\n",
      "Read in the file kmeans_61_3\n",
      "Read in the file kmeans_76_2\n",
      "Read in the file kmeans_74_2\n",
      "Read in the file kmeans_32_1\n",
      "Read in the file kmeans_43_1\n",
      "Read in the file kmeans_38_2\n",
      "Read in the file kmeans_45_2\n",
      "Read in the file kmeans_54_1\n",
      "Read in the file kmeans_87_1\n",
      "Read in the file kmeans_11_4\n",
      "Read in the file kmeans_27_4\n",
      "Read in the file kmeans_35_1\n",
      "Read in the file kmeans_49_4\n",
      "Read in the file kmeans_21_4\n",
      "Read in the file kmeans_43_4\n",
      "Read in the file kmeans_19_2\n",
      "Read in the file kmeans_89_3\n",
      "Read in the file kmeans_43_3\n",
      "Read in the file kmeans_68_3\n",
      "Read in the file kmeans_28_2\n",
      "Read in the file kmeans_39_3\n",
      "Read in the file kmeans_76_1\n",
      "Read in the file kmeans_10_3\n",
      "Read in the file kmeans_63_4\n",
      "Read in the file kmeans_94_1\n",
      "Read in the file kmeans_36_1\n",
      "Read in the file kmeans_50_3\n",
      "Read in the file kmeans_43_2\n",
      "Read in the file kmeans_81_3\n",
      "Read in the file kmeans_25_4\n",
      "Read in the file kmeans_52_4\n",
      "Read in the file kmeans_66_3\n",
      "Read in the file kmeans_25_2\n",
      "Read in the file kmeans_72_3\n",
      "Read in the file kmeans_28_4\n",
      "Read in the file kmeans_37_4\n",
      "Read in the file kmeans_30_3\n",
      "Read in the file kmeans_53_2\n",
      "Read in the file kmeans_98_3\n",
      "Read in the file kmeans_29_4\n",
      "Read in the file kmeans_36_2\n",
      "Read in the file kmeans_62_3\n",
      "Read in the file kmeans_24_2\n",
      "Read in the file kmeans_23_2\n",
      "Read in the file kmeans_9_3\n",
      "Read in the file kmeans_98_2\n",
      "Read in the file kmeans_42_1\n",
      "Read in the file kmeans_56_4\n",
      "Read in the file kmeans_75_3\n",
      "Read in the file kmeans_87_2\n",
      "Read in the file kmeans_22_3\n",
      "Read in the file kmeans_92_3\n",
      "Read in the file kmeans_46_1\n",
      "Read in the file kmeans_32_3\n",
      "Read in the file kmeans_33_3\n",
      "Read in the file kmeans_60_3\n",
      "Read in the file kmeans_84_1\n",
      "Read in the file kmeans_23_3\n",
      "Read in the file kmeans_78_1\n",
      "Read in the file kmeans_44_3\n",
      "Read in the file kmeans_6_2\n",
      "Read in the file kmeans_29_2\n",
      "Read in the file kmeans_31_4\n",
      "Read in the file kmeans_18_4\n",
      "Read in the file kmeans_11_3\n",
      "Read in the file kmeans_97_2\n",
      "Read in the file kmeans_64_3\n",
      "Read in the file kmeans_91_3\n",
      "Read in the file kmeans_31_1\n",
      "Read in the file kmeans_38_3\n",
      "Read in the file kmeans_100_1\n",
      "Read in the file kmeans_7_3\n",
      "Read in the file kmeans_52_1\n",
      "Read in the file kmeans_65_3\n",
      "Read in the file kmeans_7_4\n",
      "Read in the file kmeans_60_2\n",
      "Read in the file kmeans_38_1\n",
      "Read in the file kmeans_46_2\n",
      "Read in the file kmeans_85_3\n",
      "Read in the file kmeans_56_2\n",
      "Read in the file kmeans_67_2\n",
      "Read in the file kmeans_32_2\n",
      "Read in the file kmeans_12_1\n",
      "Read in the file kmeans_29_3\n",
      "Read in the file kmeans_11_1\n",
      "Read in the file kmeans_55_3\n",
      "Read in the file kmeans_39_4\n",
      "Read in the file kmeans_73_1\n",
      "Read in the file kmeans_33_4\n",
      "Read in the file kmeans_59_1\n",
      "Read in the file kmeans_100_2\n",
      "Read in the file kmeans_54_3\n",
      "Read in the file kmeans_42_3\n",
      "Read in the file kmeans_18_3\n",
      "Read in the file kmeans_33_1\n",
      "Read in the file kmeans_91_2\n",
      "Read in the file kmeans_45_4\n",
      "Read in the file kmeans_26_3\n",
      "Read in the file kmeans_80_2\n",
      "Read in the file kmeans_17_1\n",
      "Read in the file kmeans_88_3\n",
      "Read in the file kmeans_69_1\n",
      "Read in the file kmeans_35_2\n",
      "Read in the file kmeans_72_2\n",
      "Read in the file kmeans_100_3\n",
      "Read in the file kmeans_99_1\n",
      "Read in the file kmeans_13_3\n",
      "Read in the file kmeans_40_3\n",
      "Read in the file kmeans_81_2\n",
      "Read in the file kmeans_80_3\n",
      "Read in the file kmeans_70_2\n",
      "Read in the file kmeans_13_2\n",
      "Read in the file kmeans_69_2\n",
      "Read in the file kmeans_69_3\n",
      "Read in the file kmeans_6_3\n",
      "Read in the file kmeans_41_1\n",
      "Read in the file kmeans_35_3\n",
      "Read in the file kmeans_95_3\n",
      "Read in the file kmeans_36_3\n",
      "Read in the file kmeans_65_2\n",
      "Read in the file kmeans_18_2\n",
      "Read in the file kmeans_59_2\n",
      "Read in the file kmeans_10_2\n",
      "Read in the file kmeans_8_2\n",
      "Read in the file kmeans_34_1\n",
      "Read in the file kmeans_12_4\n",
      "Read in the file kmeans_95_2\n",
      "Read in the file kmeans_46_4\n",
      "Read in the file kmeans_49_1\n",
      "Read in the file kmeans_19_1\n",
      "Read in the file kmeans_26_4\n",
      "Read in the file kmeans_51_1\n",
      "Read in the file kmeans_34_3\n",
      "Read in the file kmeans_52_2\n",
      "Read in the file kmeans_61_1\n",
      "Read in the file kmeans_77_2\n",
      "Read in the file kmeans_54_2\n",
      "Read in the file kmeans_24_4\n",
      "Read in the file kmeans_97_1\n",
      "Read in the file kmeans_40_1\n",
      "Read in the file kmeans_82_1\n",
      "Read in the file kmeans_17_4\n",
      "Read in the file kmeans_30_2\n",
      "Read in the file kmeans_16_2\n",
      "Read in the file kmeans_37_3\n",
      "Read in the file kmeans_94_2\n",
      "Read in the file kmeans_48_1\n",
      "Read in the file kmeans_17_2\n",
      "Read in the file kmeans_97_3\n",
      "Read in the file kmeans_96_2\n",
      "Read in the file kmeans_48_2\n",
      "Read in the file kmeans_40_2\n",
      "Read in the file kmeans_91_1\n",
      "Read in the file kmeans_21_1\n",
      "Read in the file kmeans_52_3\n",
      "Read in the file kmeans_34_4\n",
      "Read in the file kmeans_56_3\n",
      "Read in the file kmeans_68_2\n",
      "Read in the file kmeans_29_1\n",
      "Read in the file kmeans_27_1\n",
      "Read in the file kmeans_86_3\n",
      "Read in the file kmeans_13_1\n",
      "{'kmeans_77_1': -0.16513795, 'kmeans_84_2': -0.10567739, 'kmeans_62_1': -0.16855566, 'kmeans_58_1': -0.16872086, 'kmeans_33_2': -0.15709017, 'kmeans_35_4': -0.007152892, 'kmeans_78_2': -0.10573166, 'kmeans_66_2': -0.10766936, 'kmeans_20_2': -0.07698862, 'kmeans_92_1': -0.1646959, 'kmeans_14_1': -0.059965983, 'kmeans_53_1': -0.086898305, 'kmeans_21_2': -0.15758434, 'kmeans_46_3': -0.14586292, 'kmeans_56_1': -0.16878106, 'kmeans_47_3': -0.1458524, 'kmeans_9_2': -0.08048692, 'kmeans_21_3': -0.15093008, 'kmeans_83_1': -0.16489534, 'kmeans_36_4': -0.0071466733, 'kmeans_14_3': -0.112741224, 'kmeans_82_3': -0.10041423, 'kmeans_27_2': -0.15728213, 'kmeans_65_1': -0.16848978, 'kmeans_63_1': -0.16854477, 'kmeans_99_2': -0.103262074, 'kmeans_11_2': -0.08043847, 'kmeans_28_1': -0.1132598, 'kmeans_67_1': -0.16839921, 'kmeans_94_3': -0.085256815, 'kmeans_20_4': -0.020448633, 'kmeans_79_2': -0.10571291, 'kmeans_50_1': -0.086971775, 'kmeans_64_1': -0.16853037, 'kmeans_58_2': -0.1119828, 'kmeans_5_2': 0.009220891, 'kmeans_86_2': -0.10566291, 'kmeans_9_4': 0.0087813055, 'kmeans_62_2': -0.107708804, 'kmeans_92_2': -0.10338491, 'kmeans_71_2': -0.105793916, 'kmeans_15_2': -0.08039263, 'kmeans_73_2': -0.10577632, 'kmeans_34_2': -0.1570806, 'kmeans_98_1': -0.1645482, 'kmeans_30_1': -0.113159865, 'kmeans_67_3': -0.1006533, 'kmeans_15_4': -0.02086073, 'kmeans_85_1': -0.16487484, 'kmeans_60_1': -0.16868004, 'kmeans_83_3': -0.100405775, 'kmeans_88_1': -0.16478546, 'kmeans_66_1': -0.16846918, 'kmeans_82_2': -0.10569109, 'kmeans_47_1': -0.099164695, 'kmeans_75_2': -0.10575672, 'kmeans_7_1': -0.089726076, 'kmeans_74_1': -0.16518007, 'kmeans_80_1': -0.16497336, 'kmeans_47_4': -0.013830399, 'kmeans_19_4': -0.020455774, 'kmeans_5_4': 0.008553692, 'kmeans_37_2': -0.15696882, 'kmeans_10_1': -0.060886793, 'kmeans_31_3': -0.14605162, 'kmeans_93_1': -0.16467553, 'kmeans_8_4': 0.009264582, 'kmeans_51_2': -0.19406007, 'kmeans_99_3': -0.085187264, 'kmeans_78_3': -0.100591704, 'kmeans_50_4': -0.013831247, 'kmeans_38_4': -0.0071198037, 'kmeans_41_3': -0.1459463, 'kmeans_87_3': -0.08531046, 'kmeans_7_2': -0.1438997, 'kmeans_96_1': -0.16463883, 'kmeans_12_2': -0.08043004, 'kmeans_30_4': -0.007169118, 'kmeans_20_1': -0.05503477, 'kmeans_8_1': -0.08654343, 'kmeans_83_2': -0.10568418, 'kmeans_12_3': -0.11279227, 'kmeans_70_3': -0.10057205, 'kmeans_22_4': -0.0072963713, 'kmeans_28_3': -0.14618574, 'kmeans_26_2': -0.15734819, 'kmeans_88_2': -0.1056449, 'kmeans_51_4': -0.013826247, 'kmeans_41_4': -0.013868197, 'kmeans_95_1': -0.16464923, 'kmeans_14_4': -0.020904746, 'kmeans_85_2': -0.10566952, 'kmeans_44_2': -0.19437993, 'kmeans_84_3': -0.10040509, 'kmeans_57_1': -0.1687362, 'kmeans_39_1': -0.11261356, 'kmeans_25_1': -0.11329466, 'kmeans_62_4': -0.025162678, 'kmeans_49_3': -0.14583822, 'kmeans_37_1': -0.11293377, 'kmeans_63_3': -0.10056241, 'kmeans_48_3': -0.14584923, 'kmeans_54_4': -0.01379175, 'kmeans_57_2': -0.11199972, 'kmeans_6_1': -0.089798234, 'kmeans_77_3': -0.10060261, 'kmeans_22_2': -0.15756091, 'kmeans_81_1': -0.16493171, 'kmeans_75_1': -0.16516906, 'kmeans_22_1': -0.091501765, 'kmeans_42_2': -0.1944488, 'kmeans_15_3': -0.11272514, 'kmeans_44_4': -0.013838582, 'kmeans_58_3': -0.10068161, 'kmeans_10_4': 0.008784442, 'kmeans_17_3': -0.11268487, 'kmeans_86_1': -0.16485639, 'kmeans_55_1': -0.16880304, 'kmeans_19_3': -0.11265878, 'kmeans_24_3': -0.15087098, 'kmeans_79_3': -0.100550085, 'kmeans_16_1': -0.05994969, 'kmeans_90_1': -0.1647445, 'kmeans_93_3': -0.08526466, 'kmeans_53_3': -0.14580117, 'kmeans_89_1': -0.164778, 'kmeans_55_2': -0.11201619, 'kmeans_63_2': -0.10770145, 'kmeans_76_3': -0.100612804, 'kmeans_23_1': -0.06444902, 'kmeans_45_3': -0.14591447, 'kmeans_90_3': -0.08528358, 'kmeans_25_3': -0.14630382, 'kmeans_39_2': -0.15695335, 'kmeans_27_3': -0.14620456, 'kmeans_6_4': 0.008946361, 'kmeans_74_3': -0.100657396, 'kmeans_96_3': -0.085239455, 'kmeans_89_2': -0.10366949, 'kmeans_61_2': -0.10771664, 'kmeans_57_3': -0.10050112, 'kmeans_72_1': -0.1652404, 'kmeans_20_3': -0.1126566, 'kmeans_26_1': -0.11327873, 'kmeans_71_1': -0.16525781, 'kmeans_15_1': -0.05995589, 'kmeans_59_3': -0.10065512, 'kmeans_18_1': -0.055046342, 'kmeans_64_2': -0.10769226, 'kmeans_71_3': -0.100566335, 'kmeans_5_3': 0.0029939148, 'kmeans_51_3': -0.14581753, 'kmeans_93_2': -0.10336833, 'kmeans_50_2': -0.19408792, 'kmeans_5_1': -0.09015808, 'kmeans_79_1': -0.16504617, 'kmeans_24_1': -0.06444239, 'kmeans_41_2': -0.19447623, 'kmeans_70_1': -0.16530186, 'kmeans_90_2': -0.10366554, 'kmeans_13_4': -0.021022297, 'kmeans_47_2': -0.19418901, 'kmeans_16_3': -0.11270576, 'kmeans_49_2': -0.19411962, 'kmeans_9_1': -0.08653631, 'kmeans_23_4': -0.0072900727, 'kmeans_68_1': -0.16838768, 'kmeans_45_1': -0.09917468, 'kmeans_73_3': -0.10066619, 'kmeans_31_2': -0.15718286, 'kmeans_14_2': -0.08040777, 'kmeans_16_4': -0.020854212, 'kmeans_32_4': -0.0071716574, 'kmeans_8_3': -0.11284373, 'kmeans_44_1': -0.099185444, 'kmeans_61_3': -0.100613184, 'kmeans_76_2': -0.105749145, 'kmeans_74_2': -0.10576956, 'kmeans_32_1': -0.113120444, 'kmeans_43_1': -0.09922148, 'kmeans_38_2': -0.15696391, 'kmeans_45_2': -0.19428812, 'kmeans_54_1': -0.086892396, 'kmeans_87_1': -0.16481268, 'kmeans_11_4': 0.008793737, 'kmeans_27_4': -0.007182162, 'kmeans_35_1': -0.11300618, 'kmeans_49_4': -0.01382895, 'kmeans_21_4': -0.0072956043, 'kmeans_43_4': -0.013845716, 'kmeans_19_2': -0.07699564, 'kmeans_89_3': -0.085293345, 'kmeans_43_3': -0.14593048, 'kmeans_68_3': -0.10059863, 'kmeans_28_2': -0.15725923, 'kmeans_39_3': -0.14597082, 'kmeans_76_1': -0.1651546, 'kmeans_10_3': -0.11280292, 'kmeans_63_4': -0.025155379, 'kmeans_94_1': -0.16465749, 'kmeans_36_1': -0.11293085, 'kmeans_50_3': -0.14583251, 'kmeans_43_2': -0.19439957, 'kmeans_81_3': -0.10043477, 'kmeans_25_4': -0.0072642537, 'kmeans_52_4': -0.013827439, 'kmeans_66_3': -0.1006927, 'kmeans_25_2': -0.1573731, 'kmeans_72_3': -0.100551434, 'kmeans_28_4': -0.0071760686, 'kmeans_37_4': -0.007121024, 'kmeans_30_3': -0.14605393, 'kmeans_53_2': -0.1939771, 'kmeans_98_3': -0.08519435, 'kmeans_29_4': -0.00717583, 'kmeans_36_2': -0.15704365, 'kmeans_62_3': -0.1005819, 'kmeans_24_2': -0.15742607, 'kmeans_23_2': -0.15747836, 'kmeans_9_3': -0.11283911, 'kmeans_98_2': -0.10331119, 'kmeans_42_1': -0.099230744, 'kmeans_56_4': -0.025242269, 'kmeans_75_3': -0.10061841, 'kmeans_87_2': -0.10565221, 'kmeans_22_3': -0.15092406, 'kmeans_92_3': -0.08527038, 'kmeans_46_1': -0.09916407, 'kmeans_32_3': -0.14604808, 'kmeans_33_3': -0.14604089, 'kmeans_60_3': -0.10063933, 'kmeans_84_1': -0.16488627, 'kmeans_23_3': -0.15091404, 'kmeans_78_1': -0.16505331, 'kmeans_44_3': -0.14592332, 'kmeans_6_2': 0.0092312265, 'kmeans_29_2': -0.15722479, 'kmeans_31_4': -0.0071711782, 'kmeans_18_4': -0.020456083, 'kmeans_11_3': -0.11279893, 'kmeans_97_2': -0.10332252, 'kmeans_64_3': -0.1005435, 'kmeans_91_3': -0.08527698, 'kmeans_31_1': -0.113148846, 'kmeans_38_3': -0.14597787, 'kmeans_100_1': -0.1645334, 'kmeans_7_3': 0.0036093614, 'kmeans_52_1': -0.086937115, 'kmeans_65_3': -0.10053703, 'kmeans_7_4': 0.008967861, 'kmeans_60_2': -0.107735954, 'kmeans_38_1': -0.112893924, 'kmeans_46_2': -0.19428122, 'kmeans_85_3': -0.0853506, 'kmeans_56_2': -0.112006776, 'kmeans_67_2': -0.10766217, 'kmeans_32_2': -0.15710609, 'kmeans_12_1': -0.05998778, 'kmeans_29_3': -0.14616758, 'kmeans_11_1': -0.059994653, 'kmeans_55_3': -0.10055334, 'kmeans_39_4': -0.0071138963, 'kmeans_73_1': -0.16521296, 'kmeans_33_4': -0.0071750456, 'kmeans_59_1': -0.16869514, 'kmeans_100_2': -0.13752909, 'kmeans_54_3': -0.1457909, 'kmeans_42_3': -0.1459374, 'kmeans_18_3': -0.112673275, 'kmeans_33_1': -0.113098405, 'kmeans_91_2': -0.10340444, 'kmeans_45_4': -0.013852214, 'kmeans_26_3': -0.14621165, 'kmeans_80_2': -0.10570579, 'kmeans_17_1': -0.055060778, 'kmeans_88_3': -0.08530024, 'kmeans_69_1': -0.16838123, 'kmeans_35_2': -0.15706891, 'kmeans_72_2': -0.105789155, 'kmeans_100_3': -0.085166916, 'kmeans_99_1': -0.16453879, 'kmeans_13_3': -0.11275355, 'kmeans_40_3': -0.1459535, 'kmeans_81_2': -0.10569867, 'kmeans_80_3': -0.10048232, 'kmeans_70_2': -0.10580963, 'kmeans_13_2': -0.080423445, 'kmeans_69_2': -0.107641935, 'kmeans_69_3': -0.100585036, 'kmeans_6_3': 0.0036021709, 'kmeans_41_1': -0.09923769, 'kmeans_35_3': -0.1460219, 'kmeans_95_3': -0.085245, 'kmeans_36_3': -0.14601044, 'kmeans_65_2': -0.107683465, 'kmeans_18_2': -0.07700322, 'kmeans_59_2': -0.111972906, 'kmeans_10_2': -0.080464356, 'kmeans_8_2': -0.08049828, 'kmeans_34_1': -0.11305937, 'kmeans_12_4': -0.021032138, 'kmeans_95_2': -0.103337504, 'kmeans_46_4': -0.013836744, 'kmeans_49_1': -0.08698214, 'kmeans_19_1': -0.055040654, 'kmeans_26_4': -0.0072357226, 'kmeans_51_1': -0.08694524, 'kmeans_34_3': -0.1460287, 'kmeans_52_2': -0.19399731, 'kmeans_61_1': -0.16863647, 'kmeans_77_2': -0.1057437, 'kmeans_54_2': -0.19396304, 'kmeans_24_4': -0.007270487, 'kmeans_97_1': -0.1646256, 'kmeans_40_1': -0.11258598, 'kmeans_82_1': -0.16491549, 'kmeans_17_4': -0.020833516, 'kmeans_30_2': -0.15720193, 'kmeans_16_2': -0.07702495, 'kmeans_37_3': -0.14599945, 'kmeans_94_2': -0.10335861, 'kmeans_48_1': -0.09913332, 'kmeans_17_2': -0.077018455, 'kmeans_97_3': -0.08521828, 'kmeans_96_2': -0.10332701, 'kmeans_48_2': -0.19417588, 'kmeans_40_2': -0.15694003, 'kmeans_91_1': -0.16472848, 'kmeans_21_1': -0.065470435, 'kmeans_52_3': -0.14581023, 'kmeans_34_4': -0.007176428, 'kmeans_56_3': -0.10053565, 'kmeans_68_2': -0.107655145, 'kmeans_29_1': -0.113168314, 'kmeans_27_1': -0.11326269, 'kmeans_86_3': -0.085326105, 'kmeans_13_1': -0.059972625}\n"
     ]
    }
   ],
   "source": [
    "# this should supposedly make the above slightly faster and run in exactly the same way. \n",
    "import os\n",
    "import anndata as ad\n",
    "import glob\n",
    "\n",
    "# Directory containing the h5ad files\n",
    "directory = '/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/fibroblast_typing_9_20_n/output_kmeans/'\n",
    "\n",
    "# Combined dictionary to store silhouette scores\n",
    "combined_silhouette_scores = {}\n",
    "\n",
    "# Get list of .h5ad files in the directory\n",
    "h5ad_files = glob.glob(os.path.join(directory, '*.h5ad'))\n",
    "\n",
    "# Loop through each file\n",
    "for filepath in h5ad_files:\n",
    "    # Parse the filename from the filepath\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) < 4:\n",
    "        continue  # Skip any files that don't match the expected pattern\n",
    "\n",
    "    # Extract n_clusters and run from filename\n",
    "    n_clusters = parts[2]\n",
    "    run = parts[3]\n",
    "\n",
    "    # Load the h5ad file in read-only mode\n",
    "    adata = ad.read_h5ad(filepath, backed='r')\n",
    "    print(f\"Read in the file kmeans_{n_clusters}_{run}\")\n",
    "\n",
    "    # Extract silhouette score from the AnnData object\n",
    "    key = f'kmeans_{n_clusters}_{run}'\n",
    "    score = adata.uns['silhouette_scores'].get(key)\n",
    "\n",
    "    # Add to combined dictionary if the score exists\n",
    "    if score is not None:\n",
    "        combined_silhouette_scores[key] = score\n",
    "\n",
    "# Now `combined_silhouette_scores` contains the combined dictionary from all files\n",
    "print(combined_silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b3f82d-9688-4d6d-bf22-08f55319ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "save_dir = '/home/oliven/scFoundationModels/notebooks/reprogramming/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Define the full path for the JSON file\n",
    "save_path = os.path.join(save_dir, 'combined_silhouette_scores.json')\n",
    "\n",
    "# Convert any float32 values to float\n",
    "combined_silhouette_scores_serializable = {key: float(value) for key, value in combined_silhouette_scores.items()}\n",
    "\n",
    "# Save the silhouette scores to the JSON file\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(combined_silhouette_scores_serializable, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b59c3e-d086-479d-9f52-c0e3d825c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting x (n_clusters) and y (silhouette scores)\n",
    "n_clusters = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for key, score in combined_silhouette_scores.items():\n",
    "    # Extract n_clusters from the key 'kmeans_n_clusters_run'\n",
    "    parts = key.split('_')\n",
    "    n_clusters.append(int(parts[1]))  # n_clusters is the second part\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Convert lists to numpy arrays for plotting\n",
    "n_clusters = np.array(n_clusters)\n",
    "silhouette_scores = np.array(silhouette_scores)\n",
    "\n",
    "# Create scatterplot\n",
    "plt.scatter(n_clusters, silhouette_scores, color='blue', label='Silhouette Scores')\n",
    "\n",
    "# Fit a 2nd-degree polynomial to the data (quadratic fit)\n",
    "coefficients = np.polyfit(n_clusters, silhouette_scores, 2)\n",
    "polynomial = np.poly1d(coefficients)\n",
    "\n",
    "# Create x-values for the line of best fit\n",
    "x_fit = np.linspace(min(n_clusters), max(n_clusters), 100)\n",
    "y_fit = polynomial(x_fit)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x_fit, y_fit, color='red', label='Quadratic Fit')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Scores vs. Number of Clusters for TS Fibroblast Typing')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfdc4c-6985-41d7-a855-d97f5a9b929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6358113e-a0bc-4b5c-8e33-fdb4ecac0ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb487f-0a53-4ad6-83b8-7d82d2342273",
   "metadata": {},
   "source": [
    "# Day 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54261b2b-fcda-4e0f-90e3-eef3b4ad1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('data/HumanTFs_v_1.01.csv') # now comes from csv file and not straight from web\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "\n",
    "adata.var['ensemblid'] = adata.var['ensemblid'].str.split('.').str[0] # JP Add this line\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a682730-805b-4088-b0ac-c9c87f93778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "\n",
    "# # Normalize and log-transform the data\n",
    "# sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "# sc.pp.log1p(adata)\n",
    "\n",
    "# # Extract the count matrix and ensure it is a dense NumPy array\n",
    "# X = adata.X\n",
    "\n",
    "# # Convert sparse matrix to dense if necessary\n",
    "# if hasattr(X, 'toarray'):\n",
    "#     X = X.toarray()\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # List of cluster numbers to test\n",
    "# cluster_numbers = list(range(2, 101))\n",
    "\n",
    "# # Number of runs per cluster number\n",
    "# n_runs = 3\n",
    "\n",
    "# # Loop over cluster numbers and runs\n",
    "# for n_clusters in cluster_numbers:\n",
    "#     for run in range(1, n_runs + 1):\n",
    "#         # Print the current iteration\n",
    "#         print(f\"Now clustering kmeans_{n_clusters}_{run}:\")\n",
    "        \n",
    "#         # Perform K-means clustering\n",
    "#         kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=1, random_state=42 + run)\n",
    "#         adata.obs[f'kmeans_{n_clusters}_{run}'] = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "#         # Print that the results have been written to adata.obs\n",
    "#         print(f\"kmeans_{n_clusters}_{run} has been written to obs\")\n",
    "\n",
    "# # Check the updated obs\n",
    "# print(adata.obs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ed702-ac8e-4d35-95e3-72e853386d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Normalize and log-transform the data\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# Extract the count matrix and ensure it is a dense NumPy array\n",
    "X = adata.X\n",
    "\n",
    "# Convert sparse matrix to dense if necessary\n",
    "if hasattr(X, 'toarray'):\n",
    "    X = X.toarray()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# List of cluster numbers to test\n",
    "cluster_numbers = list(range(5, 50))\n",
    "\n",
    "# Number of runs per cluster number\n",
    "n_runs = 3\n",
    "\n",
    "# Initialize dictionary to store silhouette scores\n",
    "silhouette_scores = {n: [] for n in cluster_numbers}\n",
    "\n",
    "# Loop over cluster numbers and runs\n",
    "for n_clusters in cluster_numbers:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Print the current iteration\n",
    "        print(f\"Now clustering kmeans_{n_clusters}_{run}:\")\n",
    "        \n",
    "        # Perform K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=1, random_state=42 + run)\n",
    "        cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "        adata.obs[f'kmeans_{n_clusters}_{run}'] = cluster_labels\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        if n_clusters > 1:  # Silhouette score is only defined for n_clusters > 1\n",
    "            score = silhouette_score(X_scaled, cluster_labels)\n",
    "            silhouette_scores[n_clusters].append(score)\n",
    "            print(f\"Silhouette score for kmeans_{n_clusters}_{run}: {score:.4f}\")\n",
    "        else:\n",
    "            silhouette_scores[n_clusters].append(None)\n",
    "            print(f\"Silhouette score for kmeans_{n_clusters}_{run}: Not applicable (n_clusters <= 1)\")\n",
    "\n",
    "        # Print that the results have been written to adata.obs\n",
    "        print(f\"kmeans_{n_clusters}_{run} has been written to obs\")\n",
    "\n",
    "# Print the silhouette scores dictionary\n",
    "print(\"Silhouette scores dictionary:\")\n",
    "print(silhouette_scores)\n",
    "\n",
    "# Check the updated obs\n",
    "print(adata.obs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77faea71-7986-47f3-ad8e-9d58d7681697",
   "metadata": {},
   "source": [
    "# Day 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb14c7-d3e8-45e6-b7fd-d03e8bacf0ca",
   "metadata": {},
   "source": [
    "## Summarize the fibroblast data in adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ffca9-b31b-4699-8791-86b67a1cfb47",
   "metadata": {},
   "source": [
    "### General informtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bf576-b2d9-4203-874a-4f94e13880e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('data/HumanTFs_v_1.01.csv') # now comes from csv file and not straight from web\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "\n",
    "adata.var['ensemblid'] = adata.var['ensemblid'].str.split('.').str[0] # JP Add this line\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4764818-4f04-41c9-ba0a-4b45e5f72668",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['donor'].values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0bb37-5436-406a-9a2f-b1eb80a66e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d7c9e-d6d9-4fb3-b034-8936db373371",
   "metadata": {},
   "source": [
    "### Which are TFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91a100-b638-41ff-b61f-9be1a70c89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a885331-00d0-4e0b-85dc-ee9f9ad810f2",
   "metadata": {},
   "source": [
    "# Day 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac4679-a2a6-4589-a790-c7e91f8173ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Copied from Joshua's notebook, which was copied from mine. Theoretically, this should be Day 10 work with minor changes / debugging,\n",
    "and this is the code the SLURM job is based on.\n",
    "IMPORTANT QUESTION (review code): When we translate gene names from one type to another, are their names actually being updated in either the Human TFs csv or in the adata object?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a2cc3-d1e8-4ca4-a74d-ab1987e2baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('data/HumanTFs_v_1.01.csv') # now comes from csv file and not straight from web\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "\n",
    "adata.var['ensemblid'] = adata.var['ensemblid'].str.split('.').str[0] # JP Add this line\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c1246-cedc-4551-83e1-ec9212e3fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_ids(list):\n",
    "    # Extract base IDs from list_b by removing version numbers\n",
    "    new_list = [id.split('.')[0] for id in list]\n",
    "    return new_list\n",
    "\n",
    "#ensembl ids from the counts matrix\n",
    "counts_ensid_list = adata.var['ensemblid'].values.tolist()\n",
    "\n",
    "# there were version numbers ending with \" .'#' \" that needed to be removed\n",
    "counts_ensid_list = translate_ids(counts_ensid_list)\n",
    "\n",
    "\n",
    "# ensembl ids from the transcription factor list, which in this case is also the perturbation list (testing one at a time)\n",
    "tf_ensid_list = df['Ensembl ID'].values.tolist()\n",
    "\n",
    "\n",
    "def validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "    missing_tfs = []\n",
    "    for TF in tf_ensid_list:\n",
    "        if TF not in counts_ensid_list:\n",
    "            missing_tfs.append(TF)\n",
    "    \n",
    "    if missing_tfs:\n",
    "        print(\"TFs not found in counts_ensid_list:\")\n",
    "        for tf in missing_tfs:\n",
    "            print(tf)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "validate_ensembl_tfs(tf_ensid_list, counts_ensid_list)\n",
    "\n",
    "# when we perturb each tf in tf_ensid_list, we are just going to skip the one problematic one\n",
    "problem_ens_ids = ['ZNF73_HUMAN', 'ENSG00000204828', 'DUX1_HUMAN', 'DUX3_HUMAN', 'ENSG00000262156', 'ENSG00000196101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab2ee5-0c63-40f6-b214-2b6d605713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tf_ensid_list))\n",
    "print(len(problem_ens_ids))\n",
    "tf_ensid_list = [id for id in tf_ensid_list if id not in problem_ens_ids]\n",
    "print(len(tf_ensid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bb523-c283-47f5-a756-59958fcb60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_perturb_id_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_id_counts(adata_temp, tf_list, scalar) # JP change this line\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_id_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['ensemblid'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['ensemblid'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "\n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.obs['U'] = scalar  # Default value for genes not in tf_list\n",
    "    # adata.var = \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5abc5-2d5c-49b6-93fc-8f0dfc8aa9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # JP change this line (all imports go at the top !)\n",
    "\n",
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/all-tfs\"\n",
    "scalars = [0.5, 0.75, 1.001]\n",
    "\n",
    "# Filter tf_ensid_list to remove problematic Ensembl IDs\n",
    "tf_ensid_list = [id for id in tf_ensid_list if id not in problem_ens_ids]\n",
    "print(f\"Total Ensembl IDs to process: {len(tf_ensid_list)}\")\n",
    "\n",
    "# Clean Ensembl IDs in adata.var['ensemblid'] to remove anything after '.'\n",
    "cleaned_ensembl_ids = adata.var['ensemblid'].str.split('.').str[0]\n",
    "\n",
    "for i in range(len(tf_ensid_list)):\n",
    "    try:\n",
    "        print(f\"\\nProcessing index: {i}\")\n",
    "        val = df['Ensembl ID'].iloc[i]\n",
    "        TFs = val.split()  # Split in case there are multiple TFs\n",
    "        print(f\"Current TFs: {TFs}\")\n",
    "\n",
    "        # Check if all TFs are in the cleaned Ensembl IDs\n",
    "        missing_in_adata = [tf for tf in TFs if tf not in cleaned_ensembl_ids.values]\n",
    "        if missing_in_adata:\n",
    "            print(f\"Skipping missing genes: {missing_in_adata}\")\n",
    "            continue  # Skip this set of TFs if any are missing\n",
    "\n",
    "        # Validate TFs with counts_ensid_list\n",
    "        if validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "            TFs_str = \"_\".join(TFs)\n",
    "            output_path = os.path.join(output_directory, f\"{TFs_str}.h5ad\")\n",
    "\n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"{output_path} already exists: continuing to next TF!\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Perturbing TFs: {TFs}\")\n",
    "            adataDict = iterate_perturb_id_counts(adata.copy(), TFs, scalars)\n",
    "\n",
    "            # Concatenate all AnnData objects along the observations axis\n",
    "            concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "            # Copy var information from the original AnnData\n",
    "            concatenated_adata.var = adata.var.copy()\n",
    "\n",
    "            # JP remove the below lines. They were specific to reprogramming information but not important for the human TF\n",
    "            # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "            # concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "            # concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "            # concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "            # concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "            # concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "            # concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "            # concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "            # concatenated_adata.obs\n",
    "            \n",
    "            # Save the concatenated AnnData object to the file\n",
    "            concatenated_adata.write_h5ad(output_path)\n",
    "            print(\"    File created successfully\")\n",
    "        else:\n",
    "            print(f\"The file made from {val} could not be created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered at index {i}: {e}\")\n",
    "\n",
    "print('All recipes complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32895a8-0682-4350-96a3-4c83d9e1b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f127a7-839c-4232-8507-3f78fa41bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d943dc-4396-42fe-b736-103d5d647760",
   "metadata": {},
   "source": [
    "# Day 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209edff-4229-4a0c-a833-0638eed7342c",
   "metadata": {},
   "source": [
    "## Load Data (prev day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1294c-24df-4d55-b991-68234685928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Jpickard1/scFoundationModels/main/notebooks/reprogramming/data/HumanTFs_v_1.01.csv')\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764a4f8-37bf-4aed-a35a-2af9c32329f0",
   "metadata": {},
   "source": [
    "## Check for invalid ensembl ids (day 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d8ef0-0eb4-4523-955e-b2798e5e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_ids(list):\n",
    "    # Extract base IDs from list_b by removing version numbers\n",
    "    new_list = [id.split('.')[0] for id in list]\n",
    "    return new_list\n",
    "\n",
    "#ensembl ids from the counts matrix\n",
    "counts_ensid_list = adata.var['ensemblid'].values.tolist()\n",
    "# there were version numbers ending with \" .'#' \" that needed to be removed\n",
    "counts_ensid_list = translate_ids(counts_ensid_list)\n",
    "\n",
    "\n",
    "# ensembl ids from the transcription factor list, which in this case is also the perturbation list (testing one at a time)\n",
    "tf_ensid_list = df['Ensembl ID'].values.tolist()\n",
    "\n",
    "# def validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "#     for TF in tf_ensid_list:\n",
    "#         if TF not in counts_ensid_list:\n",
    "#             print(TF)\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "\n",
    "def validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "    missing_tfs = []\n",
    "    for TF in tf_ensid_list:\n",
    "        if TF not in counts_ensid_list:\n",
    "            missing_tfs.append(TF)\n",
    "    \n",
    "    if missing_tfs:\n",
    "        print(\"TFs not found in counts_ensid_list:\")\n",
    "        for tf in missing_tfs:\n",
    "            print(tf)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "validate_ensembl_tfs(tf_ensid_list, counts_ensid_list)\n",
    "\n",
    "# when we perturb each tf in tf_ensid_list, we are just going to skip the one problematic one\n",
    "problem_ens_ids = ['ZNF73_HUMAN', 'ENSG00000204828', 'DUX1_HUMAN', 'DUX3_HUMAN', 'ENSG00000262156', 'ENSG00000196101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec21c30-6c8b-40a8-82ac-44d7d4842030",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tf_ensid_list))\n",
    "print(len(problem_ens_ids))\n",
    "tf_ensid_list = [id for id in tf_ensid_list if id not in problem_ens_ids]\n",
    "print(len(tf_ensid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a640db-48d1-409e-a836-763d9cc93eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.head()  # Display the first 10 gene names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0f84b-55a5-4f1f-8a83-55d0ae5288bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few cleaned Ensembl IDs to verify the format\n",
    "print(cleaned_ensembl_ids[:10])\n",
    "\n",
    "# Check if the specific missing gene is in the cleaned list\n",
    "print('ENSG00000137203' in cleaned_ensembl_ids.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191db3b-890b-493a-913f-e8b6cd6ac484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_perturb_id_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_id_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_id_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['ensemblid'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['ensemblid'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "\n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.obs['U'] = scalar  # Default value for genes not in tf_list\n",
    "    # adata.var = \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537631a6-0137-40c7-afbd-cefdf0d23a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/all-tfs\"\n",
    "scalars = [0.5, 0.75, 1.001, 1.25, 1.5]\n",
    "\n",
    "# Filter tf_ensid_list to remove problematic Ensembl IDs\n",
    "tf_ensid_list = [id for id in tf_ensid_list if id not in problem_ens_ids]\n",
    "print(f\"Total Ensembl IDs to process: {len(tf_ensid_list)}\")\n",
    "\n",
    "# Clean Ensembl IDs in adata.var['ensemblid'] to remove anything after '.'\n",
    "cleaned_ensembl_ids = adata.var['ensemblid'].str.split('.').str[0]\n",
    "\n",
    "for i in range(len(tf_ensid_list)):\n",
    "    try:\n",
    "        print(f\"\\nProcessing index: {i}\")\n",
    "        val = df['Ensembl ID'].iloc[i]\n",
    "        TFs = val.split()  # Split in case there are multiple TFs\n",
    "        print(f\"Current TFs: {TFs}\")\n",
    "\n",
    "        # Check if all TFs are in the cleaned Ensembl IDs\n",
    "        missing_in_adata = [tf for tf in TFs if tf not in cleaned_ensembl_ids.values]\n",
    "        if missing_in_adata:\n",
    "            print(f\"Skipping missing genes: {missing_in_adata}\")\n",
    "            continue  # Skip this set of TFs if any are missing\n",
    "        \n",
    "        # Validate TFs with counts_ensid_list\n",
    "        if validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "            TFs_str = \"_\".join(TFs)\n",
    "            output_path = os.path.join(output_directory, f\"{TFs_str}.h5ad\")\n",
    "\n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"{output_path} already exists: continuing to next TF!\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Perturbing TFs: {TFs}\")\n",
    "            adataDict = iterate_perturb_id_counts(adata.copy(), TFs, scalars)\n",
    "\n",
    "            # Concatenate all AnnData objects along the observations axis\n",
    "            concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "            # Copy var information from the original AnnData\n",
    "            concatenated_adata.var = adata.var.copy()\n",
    "\n",
    "            # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "            concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "            concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "            concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "            concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "            concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "            concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "            concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "\n",
    "            # Save the concatenated AnnData object to the file\n",
    "            concatenated_adata.write_h5ad(output_path)\n",
    "            print(\"    File created successfully\")\n",
    "        else:\n",
    "            print(f\"The file made from {val} could not be created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered at index {i}: {e}\")\n",
    "\n",
    "print('All recipes complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d95af1-336d-48d7-870e-5ee4d98272cc",
   "metadata": {},
   "source": [
    "## Perform perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c2462-5607-47cf-99b5-5d52837b1b5d",
   "metadata": {},
   "source": [
    "### Perturbation function definitions (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae9936-4f9c-4108-8cf4-64aca74682db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iterate_perturb_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "\n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.obs['U'] = scalar  # Default value for genes not in tf_list\n",
    "    # adata.var = \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc240769-f15a-4086-9fb6-eacb0323041e",
   "metadata": {},
   "source": [
    "### Saving perturbations (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2df680-d997-4f01-8bd3-0cdefa87ccf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/all-tfs\"\n",
    "scalars = [0.5, 0.75, 1.001, 1.25, 1.5]\n",
    "print(len(tf_ensid_list))\n",
    "\n",
    "tf_ensid_list = [id for id in tf_ensid_list if id not in problem_ens_ids]\n",
    "print(len(tf_ensid_list))\n",
    "\n",
    "for i in range(len(tf_ensid_list)):\n",
    "    val = df['Ensembl ID'].iloc[i]\n",
    "    # this handles the case where there is more than one tf to perturb in the same file, but in this case there is just the one\n",
    "    TFs = val.split()\n",
    "    # take out all the ensembl ids where there was no match in the couns matrix\n",
    "\n",
    "    if validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "        # Join the TFs list into a string for the filename\n",
    "        TFs_str = \"_\".join(TFs)\n",
    "        \n",
    "        # Generate the file path for saving\n",
    "        file_name = f\"{TFs_str}.h5ad\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(output_path + \" already exists: continue!\")\n",
    "            continue\n",
    "        \n",
    "        print(TFs)\n",
    "        adataDict = iterate_perturb_counts(adata.copy(), TFs, scalars)\n",
    "\n",
    "        # Concatenate all AnnData objects along the observations axis\n",
    "        concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "        # This is the line was added today to fix the bug\n",
    "        concatenated_adata.var = adata.var.copy()\n",
    "\n",
    "        # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "        concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "        concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "        concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "        concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "        concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "        concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "        concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "        \n",
    "        # Save the concatenated AnnData object to the file\n",
    "        concatenated_adata.write_h5ad(output_path)\n",
    "        print(\"    file created\")\n",
    "    else:\n",
    "        print(\"The file made from \", val ,\" could not be created\")\n",
    "print('All recipes complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b933c-c244-4afe-bc09-1c2ee8307ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TFs are in adata\n",
    "# missing_genes = [tf for tf in TFs if tf not in adata.var.index]\n",
    "# if missing_genes:\n",
    "#     print(f\"Missing genes in AnnData object: {missing_genes}\")\n",
    "\n",
    "adata.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c80541-cc8f-4536-8e52-f660945d8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tf_ensid_list)):\n",
    "    print(f\"Processing index {i}\")\n",
    "    val = df['Ensembl ID'].iloc[i]\n",
    "    TFs = val.split()\n",
    "    \n",
    "    print(f\"TFs: {TFs}\")\n",
    "    \n",
    "    tf_ensid_list_filtered = [id for id in problem_ens_ids if id not in tf_ensid_list]\n",
    "    \n",
    "    if not validate_ensembl_tfs(counts_ensid_list, tf_ensid_list_filtered):\n",
    "        print(\"Validation failed\")\n",
    "        continue\n",
    "    \n",
    "    TFs_str = \"_\".join(TFs)\n",
    "    file_name = f\"{TFs_str}.h5ad\"\n",
    "    output_path = os.path.join(output_directory, file_name)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"{output_path} already exists\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Creating file: {output_path}\")\n",
    "    \n",
    "    adataDict = iterate_perturb_counts(adata.copy(), TFs, scalars)\n",
    "    concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "    concatenated_adata.var = adata.var.copy()\n",
    "    \n",
    "    concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "    concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "    concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "    concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "    concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "    concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "    concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "    \n",
    "    concatenated_adata.write_h5ad(output_path)\n",
    "    print(f\"File created: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fe09e-bee4-4666-9176-9282a8418120",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2570800-7f27-4621-910d-568cafd6ddbb",
   "metadata": {},
   "source": [
    "# Day 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0065148-4b7e-4a1d-98ad-b4f429e2029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generating the perturbation files for all of the Human TFs (perturbation of 1, individually). \n",
    "Day 8 is designed for the paper spreadsheet, but some of the TFs column is still not formatted properly (not fixing this today)\n",
    "\"\"\"\n",
    "\"\"\" Important: Some of the same variable names are being used in the all tf experiment as in the paper experiment: both in the same situations, e.g. TFs is the TFs, but different ones between experiments\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba6f88-8b01-430c-99c8-d6d00bd7f083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bd3a9ca-d3a0-4351-a538-e64e270cbb0e",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad760306-773a-4bed-b655-8a8d2ac9dce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import os\n",
    "\n",
    "def iterate_perturb_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "\n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.obs['U'] = scalar  # Default value for genes not in tf_list\n",
    "    # adata.var = \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4fba0-d09a-4989-b40d-e05d4a0533c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def translate_ids(list):\n",
    "    # Extract base IDs from list_b by removing version numbers\n",
    "    new_list = [id.split('.')[0] for id in list]\n",
    "    return new_list\n",
    "\n",
    "#ensembl ids from the counts matrix\n",
    "counts_ensid_list = adata.var['ensemblid'].values.tolist()\n",
    "counts_ensid_list = translate_ids(adata_id_list)\n",
    "\n",
    "\n",
    "# ensembl ids from the transcription factor list, which in this case is also the perturbation list (testing one at a time)\n",
    "tf_ensid_list = df['Ensembl ID'].values.tolist()\n",
    "\n",
    "\n",
    "def validate_ensembl_tfs(tf_ensid_list, counts_ensid_list):\n",
    "    for TF in ensembl_TFs:\n",
    "        if TF not in counts_ensid_list:\n",
    "            print(TF)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "validate_ensembl_tfs(tf_ensid_list, counts_ensid_list)\n",
    "\n",
    "# when we perturb each tf in tf_ensid_list, we are just going to skip the one problematic one\n",
    "problem_ens_ids = ['ZNF73_HUMAN']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0944045-cfb8-4925-b809-54c45a530223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d81d2-8c5e-403a-9f01-fb6cc8d32626",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff13f1-e4e8-42dc-8a8d-ff0eb7a97b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Jpickard1/scFoundationModels/main/notebooks/reprogramming/data/HumanTFs_v_1.01.csv')\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff81e1-ddb8-47a2-bf7b-665329fbec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/one-shot/perturbed\"\n",
    "scalars = [0.5, 0.75, 1.001]\n",
    "for i in range(len(df['TFs'])):\n",
    "    val = df['TFs'].iloc[i]\n",
    "    TFs = val.split()\n",
    "    if validateTFs(TFs, adata):\n",
    "\n",
    "        # Join the TFs list into a string for the filename\n",
    "        TFs_str = \"_\".join(TFs)\n",
    "        \n",
    "        # Generate the file path for saving\n",
    "        file_name = f\"{TFs_str}.h5ad\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(output_path + \" already exist: continue!\")\n",
    "            continue\n",
    "        \n",
    "        print(TFs)\n",
    "        adataDict = iterate_perturb_counts(adata.copy(), TFs, scalars)\n",
    "\n",
    "        # Concatenate all AnnData objects along the observations axis\n",
    "        concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "        # This is the line was added today to fix the bug\n",
    "        concatenated_adata.var = adata.var.copy()\n",
    "\n",
    "        # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "        concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "        concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "        concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "        concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "        concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "        concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "        concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "        \n",
    "        # Save the concatenated AnnData object to the file\n",
    "        concatenated_adata.write_h5ad(output_path)\n",
    "        print(\"    file created\")\n",
    "\n",
    "print('All recipes complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506c304-f7a3-453e-9f2f-e5efd8bd0395",
   "metadata": {},
   "source": [
    "## Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febad736-4b90-4e8b-a2e7-dc601e528a49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def validateTFs(TFs, adata):\n",
    "#     adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "#     for TF in TFs:\n",
    "#         if TF not in adata_gene_list:\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# # # to contrast the previous experiment, here genes are named by ensembl id rather than one of their names\n",
    "# ensembl_TFs = df['Ensembl ID']. values.tolist()\n",
    "# # def validate_ensembl_tfs(ensembl_TFs, adata):\n",
    "# #     adata_id_list = adata.var['ensemblid'].values.tolist()\n",
    "# #     for TF in ensembl_TFs:\n",
    "# #         if TF not in adata_id_list:\n",
    "# #             return False\n",
    "# #     return True\n",
    "\n",
    "# # validate_ensembl_tfs(ensembl_TFs, adata\n",
    "\n",
    "\n",
    "\n",
    "# def validate_ensembl_tfs(ensembl_TFs, new_adata_id_list):\n",
    "#     count = 0\n",
    "#     # Extract Ensembl IDs from the adata object\n",
    "\n",
    "#     # Initialize a flag to check if all IDs are found\n",
    "#     all_found = True\n",
    "#     # Iterate through the list of Ensembl IDs to validate\n",
    "#     for TF in ensembl_TFs:\n",
    "#         if TF not in adata_id_list:\n",
    "#             # Print the missing Ensembl ID\n",
    "#             #print(f\"{TF} not found in adata.var['ensemblid']\")\n",
    "#             count += 1\n",
    "#             # Set the flag to False if an ID is missing\n",
    "#             all_found = False\n",
    "#     # Return the final status of the validation\n",
    "#     print(len(adata_id_list))\n",
    "#     print(len(ensembl_TFs))\n",
    "#     print(count)\n",
    "#     return all_found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f1079-66fb-423f-9f56-e46d81c04d2a",
   "metadata": {},
   "source": [
    "# Day 8\n",
    "\n",
    "Generatting the perturbation files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff35e5-f45f-416f-95ca-313bd921c074",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6cd062-e13d-40a5-b679-1db068d463bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import os\n",
    "\n",
    "def iterate_perturb_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "\n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.obs['U'] = scalar  # Default value for genes not in tf_list\n",
    "    # adata.var = \n",
    "    return adata\n",
    "\n",
    "def validateTFs(TFs, adata):\n",
    "    adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "    for TF in TFs:\n",
    "        if TF not in adata_gene_list:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f8409-257e-4c03-b216-62337293499c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f639abb-5181-4d2b-89bc-e070a74af38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reprogramming recipes\n",
    "df = pd.read_csv('data/recipe_table_9_6_2024.csv')\n",
    "df.head()\n",
    "\n",
    "# Load firboblast source cells\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/unperturbed\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844415e8-df65-428b-8d18-5601f57cd263",
   "metadata": {},
   "source": [
    "## Make Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c1a67-0ac0-4e94-b059-16eca9958c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/one-shot/perturbed\"\n",
    "scalars = [0.5, 0.75, 1.001]\n",
    "for i in range(len(df['TFs'])):\n",
    "    val = df['TFs'].iloc[i]\n",
    "    TFs = val.split()\n",
    "    if validateTFs(TFs, adata):\n",
    "\n",
    "        # Join the TFs list into a string for the filename\n",
    "        TFs_str = \"_\".join(TFs)\n",
    "        \n",
    "        # Generate the file path for saving\n",
    "        file_name = f\"{TFs_str}.h5ad\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(output_path + \" already exist: continue!\")\n",
    "            continue\n",
    "        \n",
    "        print(TFs)\n",
    "        adataDict = iterate_perturb_counts(adata.copy(), TFs, scalars)\n",
    "\n",
    "        # Concatenate all AnnData objects along the observations axis\n",
    "        concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "        # This is the line was added today to fix the bug\n",
    "        concatenated_adata.var = adata.var.copy()\n",
    "\n",
    "        # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "        concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "        concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "        concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "        concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "        concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "        concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "        concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "        \n",
    "        # Save the concatenated AnnData object to the file\n",
    "        concatenated_adata.write_h5ad(output_path)\n",
    "        print(\"    file created\")\n",
    "\n",
    "print('All recipes complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf4e3f-0f83-40d8-9a98-5c8e33a02d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TFs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa5087-b0ea-44c2-95c3-6bc2bec5ac89",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c74dbc-6b9f-443d-89fb-be4b752976f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42651dce-39f6-415a-a9a5-6d35695e1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05498f82-b879-4452-8d69-273a28b05d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padata = perturb_counts(adata, ['DDX11L1'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdffdb-d65c-4162-b41c-15f9edfc526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_adata = ad.concat([adata, padata], axis=0)\n",
    "concatenated_adata.var = adata.var.copy()\n",
    "concatenated_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311423c-164d-4797-abcc-553f4016b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f591c5-ea99-4235-a2a6-9100fca8b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79b7ad-c657-40c6-aaf0-9b80a1dc7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "padata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb287d2-59ac-4fbc-8887-8500217a591f",
   "metadata": {},
   "source": [
    "# Day 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982889a0-25b9-4fb4-8195-d3593c22ed67",
   "metadata": {},
   "source": [
    "# Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afe83b-fd13-436f-8dd6-1fd95fd883d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Changes to gene names and formatting are reflected in spreadsheet\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1edb3a-5d7c-4230-a2cb-5ec790935dd3",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa696c58-66b2-4eba-a1b1-b578eff3ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a489b88-60e1-4387-8d03-20c129931da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93426a-3ff0-44e1-8b41-5d5e89d56666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270230bf-4742-48c8-90ab-0ba4ded0513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['Treatment'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e2060-2c16-4f3b-9f64-cf1807778708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'P53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16'],\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "    # this one didn't show up\n",
    "    'LXH3': ['M2-LHX3', 'M2LHX3', 'CPHD3', 'LIM3'],\n",
    "    'NGN2': ['NEUROG2', 'BHLHA8', 'MATH4A', 'Math4a', 'ATOH4', 'Ngn-2', 'BHLHA8', 'Atoh4', 'NGN-2'],\n",
    "    'LMX1A': ['LMX1.1', 'LMX1', 'LMX-1.', 'DFNA7'],\n",
    "    # NF-Kb had  a strange genecards lookup\n",
    "    'NF-B': ['NFkb1', 'NFKB1'], \n",
    "    'L-MYC': ['MYCL', 'LMYC', 'BHLHe38', 'MYCL1', 'BHLHE38'],\n",
    "    'BRN2': ['POU3F2', 'BRN2', 'OCT7', 'POUF3', 'OTF7', 'Brain-2', 'OTF-7', 'Brn-2', 'Oct-7', 'N-Oct3'], \n",
    "    'NURR1': ['NR4A2', 'TINUR', 'NOT', 'HZF3', 'NURR1', 'RNR1', 'IDLDP'],\n",
    "    'SOX2': ['SRY-Box 2', 'MCOPS3', 'ANOP3'],\n",
    "    'NEUROD': ['NEUROD1', 'BHLHa3', 'BETA2', 'BHF-1', 'MODY6', 'NeuroD1', 'BHLHA3', 'T2D'],\n",
    "    'C-MYC': ['MYC', 'C-MYC', 'MYCC', 'MRTL', 'BHLHE39'],\n",
    "    # AP-2A had  a strange genecards lookup\n",
    "    'AP-2A': [' '],\n",
    "    'PAX6': ['D11S812E', 'WAGR', 'AN2', 'AN', 'AN1', 'ASGD5', 'FVH1', 'MGDA'],\n",
    "    'OSTERIX': ['SP7', 'OSX', 'OI11', 'OI12'],\n",
    "    # OCT6 had a strange genecards lookup\n",
    "    'OCT6': ['POU3F1', 'SCIP', 'OTF6', 'OTF-6'],\n",
    "   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed97378-5da6-46b7-9b51-d1b8fca15442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2881f1-9966-4946-a2c4-d27fb6de066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5db023-1ae7-46cf-a4d8-7a9eaf5b193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba1127-ee3c-478f-8298-4a738d540bc6",
   "metadata": {},
   "source": [
    "# Day 4: Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c0cbf-311c-4de6-9e83-8dae191d7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05aa9b-e46f-4a68-a047-704b9fb4effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['TFs'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d64c66-8ea7-4ea6-928e-b907f456735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'p53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16']\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932fa31-967f-4f7f-ab6b-845791e191c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0183d92-2ee0-4b6f-a711-9cdc55a23260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e04100-5836-4bb5-985b-252c739d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above list is small enough that I can manually check it.\n",
    "\n",
    "# Things to remove from word_list:\n",
    "not_genes = ['Variant', 'Large',  '(ETS', '2)', 'Knockdown', ]\n",
    "\n",
    "# Valid genes to replace/rename in word_list:\n",
    "genes_to_translate = ['LMX1A;', #'P53']\n",
    "translated_names = ['LMX1A',]\n",
    "\n",
    "# These ones might have appeared as multiple entries, etc. b/c of spacing. easiest way was to delete and add back\n",
    "genes_to_add = ['ETS2',]\n",
    "\n",
    "# replace then subtract and add. [--------------]\n",
    "new_word_list = set(word_list) - set(not_genes)\n",
    "\n",
    "# Running the function one more time to check:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b55c4-7e15-47c1-8173-4859a1a32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Renamed med_nonz to max_exp to be more accurate. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1607b7d-0394-4092-b3d7-1f5337304ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a083ac-8ec8-4b5e-8084-3299bf915df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d543ea4-8e81-4a18-8a6a-9d58cca3794f",
   "metadata": {},
   "source": [
    "# Day 4: Copied From Josh's Notebook\n",
    "\n",
    "**Focus:** check out Nats code (debug a bit) and create a few perturbations\n",
    "- changes made to NO's code:\n",
    "    1. iterate_perturb_counts: changes the order of the arguments to `adata, tf_list, scalar_list`\n",
    "    2. perturb_counts: changes the order of the arguments to `adata, tf_list, scalar_list`\n",
    "    3. perturb_counts: there was an issue with the use of `[: np.newaxis]` with respect to `max_exp`, which is a `coo_matrix` (special type of sparse matrix). Code was modified to address an issue being thrown here.\n",
    "- new function:\n",
    "    1. validateTFs(TFs, adata): this checks if all the transcription factors are present in the adata\n",
    "- pertrubation driver (`Perform Perturbations and Create new files`):\n",
    "    1. loads Fibroblast data from Tabula Sapiens\n",
    "    2. loads `.csv` file of known reprogrmaming protocols\n",
    "    3. for each set of TFs that are validated by `validateTFs`:\n",
    "        1. use `iterate_perturb_counts` to generate perturbations with scalars `[0.5, 0.75, 1]`\n",
    "        2. concatenate the dataframes to make a single dataframe\n",
    "        3. save metadata from reprogramming protocol (i.e. PMID, source/targets, etc.)\n",
    "        4. save the new anndata as a `.h5ad` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7570a-143e-42ce-9da0-092a30f2a5de",
   "metadata": {},
   "source": [
    "## Nat's Code with some modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b62fc-2de4-4c72-989b-dd5b2c2447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e22ec-6676-4879-94a7-7ecdf360fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_perturb_counts(adata, tf_list, scalar_list):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(adata_temp, tf_list, scalar)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n",
    "def perturb_counts(adata, tf_list, scalar): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] = max_exp * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = scalar  # Default value for genes not in tf_list\n",
    "    \n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5645f9-2865-4256-9a67-16714be224ba",
   "metadata": {},
   "source": [
    "## New code to validate lists of TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458b5b2-728b-4868-91ac-dd439523a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateTFs(TFs, adata):\n",
    "    adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "    for TF in TFs:\n",
    "        if TF not in adata_gene_list:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf8a3e-cbf6-4a03-810d-52d07b426076",
   "metadata": {},
   "source": [
    "## Load data and perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da050-9ac3-4a40-82fe-ff3c9f125689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/first_5_recepies_8_29_2024.csv')\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/jpic/\"\n",
    "FILE = \"fibroblast.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754f880-759d-4ceb-ad5e-c7aec8535f99",
   "metadata": {},
   "source": [
    "## Perform Perturbations and Create new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf265d-6a26-476b-826a-08997f1c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['TFs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c916f-8cca-4155-a81b-318d253ca6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/nfs/turbo/umms-indikar/shared/projects/DARPA_AI/in-silico-reprogramming/one-shot/perturbed\"\n",
    "scalars = [0.5, 0.75, 1.001]\n",
    "for i in range(len(df['TFs'])):\n",
    "    val = df['TFs'].iloc[i]\n",
    "    val = val.replace(',',' ')\n",
    "    val = val.replace(';',' ')\n",
    "    val = val.replace(':',' ')\n",
    "    TFs = val.split(' ')\n",
    "    if validateTFs(TFs, adata):\n",
    "        print(TFs)\n",
    "        adataDict = iterate_perturb_counts(adata, TFs, scalars)\n",
    "\n",
    "        # Concatenate all AnnData objects along the observations axis\n",
    "        concatenated_adata = ad.concat(list(adataDict.values()), axis=0)\n",
    "\n",
    "        # Save reprogramming metadata into the concatenated_adata.obs table\n",
    "        concatenated_adata.obs['Source_cells'] = df['Source cells'].iloc[i]\n",
    "        concatenated_adata.obs['Target_cells'] = df['Target cells'].iloc[i]\n",
    "        concatenated_adata.obs['Treatment'] = df['Treatment'].iloc[i]\n",
    "        concatenated_adata.obs['Species'] = df['Species'].iloc[i]\n",
    "        concatenated_adata.obs['Cell_Transplantation'] = df['Cell Transplantation'].iloc[i]\n",
    "        concatenated_adata.obs['Published_Year'] = df['Published Year'].iloc[i]\n",
    "        concatenated_adata.obs['PMID'] = df['PMID'].iloc[i]\n",
    "        \n",
    "        # Join the TFs list into a string for the filename\n",
    "        TFs_str = \"_\".join(TFs)\n",
    "        \n",
    "        # Generate the file path for saving\n",
    "        file_name = f\"{TFs_str}.h5ad\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "        \n",
    "        # Save the concatenated AnnData object to the file\n",
    "        concatenated_adata.write_h5ad(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3a04e-5927-424b-9a17-fb698e0d5d4b",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae743d0-4445-45da-aa67-60dbfd13aa6e",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca734bb-76c1-453b-b0bb-e2caaff6be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied from a prev day\n",
    "\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# Print the first 5 entries\n",
    "print(\"First 5 entries:\")\n",
    "print(adata_gene_list[:5])\n",
    "\n",
    "# Print the last 5 entries\n",
    "print(\"Last 5 entries:\")\n",
    "print(adata_gene_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c1301-ecaa-40f0-bcc4-aba1e08e04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside the function so I can manipulate these directly.\n",
    "# I also checked whether it matters if I do case insensitive (capitalize everything then compare) or case sensitive.\n",
    "# Unsurprisingly, case sensitive has more discrepancies (45 vs. 44), with the one extra that was picked up as \"Ptf1a\".\n",
    "# I left the case insensitive version. \n",
    "\n",
    "# get a list of words (potential genes, also includes and, + , etc. ) from the table from the review paper\n",
    "table_1_df = pd.read_csv(\"/home/oliven/scFoundationModels/notebooks/reprogramming/data/table_1_data_from_paper_9_1.csv\")\n",
    "combined_string = ' '.join(table_1_df['TFs'].astype(str)).replace(',', '')\n",
    "word_list = combined_string.split()\n",
    "\n",
    "# get a list of genes that appear in the data matrix\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "\n",
    "# New today\n",
    "def check_valid_tfs(word_list, adata_gene_list):\n",
    "\n",
    "    word_list_upper = [word.upper() for word in word_list]\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # print what does not overlap\n",
    "    not_valid_gene = set(word_list_upper) - set(adata_gene_list_upper)\n",
    "\n",
    "    print(\"Entries in the table that are not genes in the counts matrix: \")\n",
    "    \n",
    "    return list(not_valid_gene)\n",
    "    \n",
    "check_valid_tfs(word_list, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62011aea-3548-4942-847a-d17616055966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those genes with multiple aliases, checking which are valid\n",
    "# we have to worry about making this case insensitive just in case\n",
    "multiple_alias_dict = {}\n",
    "multiple_alias_dict.update({\n",
    "    'p53': ['BCC7','BMFS5', 'LFS1', 'TRP53'],\n",
    "    'OCT3/4': ['POU5F1', 'OCT3', 'OCT4', 'OTF4', 'MGC22487'],\n",
    "    'MASH1': ['HASH1', 'BHLHa46', 'ASH1', 'ASH-1', 'ASCL1'],\n",
    "    'HNF6': ['HNF6', 'HNF6A', 'ONECUT1'],\n",
    "    'HB9': ['MNX1', 'HOXHB9', 'SCRA1', 'HLXB9', 'GC07M156491', 'GC07M156786', 'GC07M150530'],\n",
    "    'PPARG2': ['PPARG', 'NR1C3', 'PPARG1', 'PPARgamma', 'PPAR-Gamma', 'PPARG5', 'CIMT1', 'GLM1'], \n",
    "    'PU.1': ['SPI1', 'SPI-A', 'SFPI1', 'SPI-1', 'OF', 'AGM10'],\n",
    "    'N-MYC': ['MYCN', 'BHLHe37', 'N-Myc', 'NMYC', 'MYCNOT', 'MYCNsORF', 'MYCNsPEP', 'BHLHE37', 'FGLDS1', 'MODED', 'MPAPA', 'ODED'],\n",
    "    # oct9 had a strange genecards lookup\n",
    "    'OCT9': ['POU3F4', 'SLC22A16']\n",
    "    'LEF-1': ['TCF1ALPHA', 'TCF7L3', 'TCF10', 'LEF1'],\n",
    "    # these next two were listed as ER71/ETV2\n",
    "    'ER71/ETV2': ['ER71', 'ETV2', 'ETSRP71'],\n",
    "    # sv40 had a strange genecards lookup\n",
    "    'SV40': [''],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f439e6-738c-4cba-8067-fc8a28af8a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1df6ef-73f6-4d86-8dfe-335d4a067b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 4, technically (migrate this)\n",
    "adata_gene_list = adata.var['gene_symbol'].values.tolist()\n",
    "def identify_gene_name_translations(multiple_alias_dict, adata_gene_list):\n",
    "    \"\"\"\n",
    "    Identifies whether any values from multiple_alias_dict appear in adata_gene_list, case-insensitive.\n",
    "    \n",
    "    Parameters:\n",
    "    multiple_alias_dict (dict): A dictionary where keys are gene names and values are lists of aliases.\n",
    "    adata_gene_list (list): A list of gene names to check against, case-insensitive.\n",
    "\n",
    "    Prints:\n",
    "    For each key, whether it was found in the gene list along with the matching values.\n",
    "    \"\"\"\n",
    "    # Convert the gene list to uppercase for case-insensitive comparison\n",
    "    adata_gene_list_upper = [gene.upper() for gene in adata_gene_list]\n",
    "\n",
    "    # Loop through each key and values in the dictionary\n",
    "    for key, values in multiple_alias_dict.items():\n",
    "        # Convert each alias to uppercase\n",
    "        values_upper = [value.upper() for value in values]\n",
    "        \n",
    "        # Check if any alias is present in the gene list\n",
    "        found_values = [value for value in values_upper if value in adata_gene_list_upper]\n",
    "        \n",
    "        # Print appropriate message based on whether any values were found\n",
    "        if found_values:\n",
    "            print(f\"{key} was found in gene list as {found_values}\")\n",
    "        else:\n",
    "            print(f\"{key} was not found in gene list.\")\n",
    "\n",
    "identify_gene_name_translations(multiple_alias_dict, adata_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00a2c8-771e-463a-bdbb-3668d31b6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above list is small enough that I can manually check it.\n",
    "\n",
    "# Things to remove from word_list:\n",
    "not_genes = ['Variant', 'Large',  '(ETS', '2)', 'Knockdown', ]\n",
    "\n",
    "# Valid genes to replace/rename in word_list:\n",
    "genes_to_translate = ['LMX1A;', #'P53']\n",
    "translated_names = ['LMX1A',]\n",
    "\n",
    "# These ones might have appeared as multiple entries, etc. b/c of spacing. easiest way was to delete and add back\n",
    "genes_to_add = ['ETS2',]\n",
    "\n",
    "# replace then subtract and add. [--------------]\n",
    "new_word_list = set(word_list) - set(not_genes)\n",
    "\n",
    "# Running the function one more time to check:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bed245-f122-47cd-bc76-814e682c23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Renamed med_nonz to max_exp to be more accurate. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee7615-c3ae-4b05-a473-e3274728c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    # Save the original state of the parameter objects, in case some tfs do not translate (failsafe)\n",
    "    original_X = adata.X.copy()\n",
    "    original_gene_mask = gene_mask.copy()\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    max_exp = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "\n",
    "    \"\"\"This is new today. v \"\"\"\n",
    "    # Raise an error if any of the gene names in tf_list do not match column names (we will manually update these in adata):\n",
    "    missing_genes = [gene for gene in tf_list if gene not in adata.var['gene_symbol'].values]\n",
    "    \n",
    "    if missing_genes:\n",
    "        # Restore original parameter objects\n",
    "        adata.X = original_X\n",
    "        gene_mask = original_gene_mask\n",
    "        raise ValueError(f\"Genes {missing_genes} not found in anndata object\")\n",
    "\n",
    "    else:\n",
    "        \"\"\" This is new today. ^ \"\"\"\n",
    "        # Apply the scaling operation to the specified genes\n",
    "        adata.X[:, gene_mask] *= max_exp[:, np.newaxis] * scalar\n",
    "        \n",
    "        # Add/Update 'scaled' column in var\n",
    "        adata.var['scaled'] = gene_mask\n",
    "        \n",
    "        # Add/Update 'scaled_by' column in var\n",
    "        adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "        adata.var.loc[gene_mask, 'scaled_by'] = max_exp[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb06cf-f71b-4c2c-b8a2-9d7b81346258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from a prev day\n",
    "\n",
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82877-b10f-48f4-894a-ebdf8117d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want each recipe (returned as a dictionary of anndata objects, one adata object for each scalar)\n",
    "def save_perturb_to_turbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0a638-b15e-4589-94d6-0275ada43a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing on one of the tf lists from the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2d9cc-78c2-4d3c-a3c2-b0710a27000c",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb10707-df05-4e7d-a9a4-bd301ab5cd69",
   "metadata": {},
   "source": [
    "## Perturbation Model Discussion\n",
    "\n",
    "E.V. = expression values\n",
    "\n",
    "Possible algorithm:\n",
    "```\n",
    "1. find highest E.V.  for a single cell\n",
    "2. find expression value of TFs being modified\n",
    "3. have a value k for the number of different concentrations we want to test\n",
    "4. choose k different amounts to increase the TFs from there measured E.V. to the 150% maximum E.V.\n",
    "   - make an arbitray choice and code it up\n",
    "```\n",
    "\n",
    "**A reasonable person could write this 10s of different ways**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206882c6-cec6-4a8b-9605-bfdc8b058823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# median nonzero value of each row\n",
    "# the w stands for working. I just dont want to screw up the original.\n",
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "adata_w\n",
    "# def median_nonzero(col):\n",
    "#     nonzero_vals = col[col != 0]  # Extract nonzero values\n",
    "#     if len(nonzero_vals) == 0:    # If no nonzero values, return NaN\n",
    "#         return np.nan\n",
    "#     return np.median(nonzero_vals)\n",
    "\n",
    "# # Apply the function to each column and store the results\n",
    "# med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=adata_w.X)\n",
    "# adata_w.var['med_nonz'] = med_nonz\n",
    "# adata_w.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d3635-dfd9-4412-9d95-cfcbfdf0fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X = adata_w.X.toarray() if not isinstance(adata_w.X, np.ndarray) else adata_w.X\n",
    "\n",
    "def median_nonzero(col):\n",
    "    nonzero_vals = col[col != 0] \n",
    "    return np.median(nonzero_vals) if len(nonzero_vals) > 0 else 0\n",
    "\n",
    "#perform and save results of fn\n",
    "med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=X)\n",
    "adata_w.var['med_nonz'] = med_nonz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06553f13-9b94-4a5f-9039-bcf183b14ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_w.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2c287-8651-4280-b369-60bcae264beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing what it looks like before tf_list changes the first 3 rows\n",
    "# Convert to dense if it's sparse and display the first five rows\n",
    "import numpy as np\n",
    "\n",
    "# Convert to a dense array if necessary\n",
    "dense_X = adata_w.X.toarray() if not isinstance(adata_w.X, np.ndarray) else adata_w.X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621349c1-2e81-4842-b701-ef86075bebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem, scaling by a factor of the max expressed gene in that cell means that you could be scaling by different genes for each cell,\n",
    "# when the cells are all of the same type. for each get the median nonzero expression\n",
    "\n",
    "# for testing purposes: v\n",
    "tf_list = ['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "tf = 'DDX11L1'\n",
    "# for testing purposes: ^\n",
    "\n",
    "#mask = adata_w.obs_names.isin(tf_list)\n",
    "mask = np.where(adata_w.var['gene_symbol'] == tf)[0]\n",
    "adata_w.X[mask, :] = adata_w.X[mask, :] * adata_w.var['med_nonz'].values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff775d-3988-4580-b7b4-c348ba958f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "(adata_w.X[mask, :] - adata.X[mask, :]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea8504-7206-427a-b4ad-5d0a58f8fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_w.X[mask, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84ecb9-b34c-4db6-82e2-b5d99fa1a35e",
   "metadata": {},
   "source": [
    "### Scaling by median nonzero entry of each gene across all cells (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a102f-4053-420a-9d04-b21410d9853d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "# FILE = \"TS_epithelial.h5ad\"\n",
    "# adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "# #tf = 'DDX11L1'\n",
    "# tf_list =['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "\n",
    "# def median_nonzero(col):\n",
    "#     nonzero_vals = col[col != 0] \n",
    "#     return np.median(nonzero_vals) if len(nonzero_vals) > 0 else 0\n",
    "\n",
    "# # requires scalar is a scalar\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # compute nonzero median expression of each gene across cells, save to var\n",
    "#     med_nonz = np.apply_along_axis(median_nonzero, axis=0, arr=adata.X)\n",
    "#     adata.var['med_nonz'] = med_nonz\n",
    "\n",
    "#     # filter by desired tf(s), and apply the nonzero_median scaling operation to only these  \n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[mask, :] = adata.X[mask, :] * adata.var['med_nonz'].values * scalar\n",
    "#     return adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1fc75-0e49-4800-9c33-d147e4bac06d",
   "metadata": {},
   "source": [
    "### Scaling by max gene expression within each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebbee6-3805-417a-9425-e99f2b8b35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version with (I believe) improper mask that was being applied to rows and not columns\n",
    "\n",
    "# import numpy as np\n",
    "# DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "# FILE = \"TS_epithelial.h5ad\"\n",
    "# adata_w = sp.read_h5ad(os.path.join(DATAPATH, FILE))\n",
    "# #tf = 'DDX11L1'\n",
    "# tf_list =['DDX11L1', 'WASH7P', 'MIR6859-1']\n",
    "\n",
    "\n",
    "# # requires scalar is a scalar\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # compute nonzero median expression of each gene across cells, save to var\n",
    "#     med_nonz = med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "\n",
    "#     # filter by desired tf(s), and apply the nonzero_median scaling operation to only these  \n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[mask, :] = adata.X[mask, :] * adata.obs['med_nonz'].values * scalar\n",
    "#     return adata\n",
    "\n",
    "# old version without extra obs and var rows telling what was scaled and by how much\n",
    "\n",
    "\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # Compute maximum expression level of each cell and save it to obs\n",
    "#     med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "    \n",
    "#     # apply operation only to genes in tf_list\n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     adata.X[:, mask] = adata.X[:, mask] * adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# version before gpt optimized\n",
    "\n",
    "# def perturb_counts(tf_list, scalar, adata): \n",
    "#     # Compute maximum expression level of each cell and save it to obs\n",
    "#     med_nonz = np.max(adata.X, axis=1)\n",
    "#     adata.obs['med_nonz'] = med_nonz\n",
    "    \n",
    "#     # Add a new obs column called 'scalar' containing the scalar value for each row\n",
    "#     adata.obs['scalar'] = scalar\n",
    "    \n",
    "#     # Create a mask for genes in tf_list\n",
    "#     mask = np.where(adata.var['gene_symbol'].isin(tf_list))[0]\n",
    "#     # Apply the scaling operation to the specified genes\n",
    "#     adata.X[:, mask] = adata.X[:, mask] * adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "    \n",
    "#     # Add a new var column called 'scaled' with True for genes in tf_list and False otherwise\n",
    "#     adata.var['scaled'] = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "#     # Add a new var column 'scaled_by'\n",
    "#     adata.var['scaled_by'] = 1\n",
    "#     # Set scaling factor for genes in tf_list\n",
    "\n",
    "#     ############I asked gpt to do this line and am unsure if it is correct. checking now.\n",
    "#     adata.var.loc[adata.var['scaled'], 'scaled_by'] = adata.obs['med_nonz'].values[:, np.newaxis] * scalar\n",
    "#     ###############\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# loop version before gpt optimized\n",
    "\n",
    "# # requires that within each perturbation, all of the transcription factors in tf_list are scaled by the same amount, that is, (scalar * \"max gene expression in that cell\")\n",
    "# # requires adata is cells x genes\n",
    "\n",
    "# import anndata\n",
    "\n",
    "# def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "#     adata_dict = {}\n",
    "    \n",
    "#     for scalar in scalar_list:\n",
    "#         adata_temp = adata.copy()\n",
    "#         perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "#         adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "#     return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99114ac8-38af-488b-8856-acc26632b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Josh, please read: the adata.obs['scalar'] = scalar copies the scalar down for that call, associated with every cell in X. Same with ['scaled'] and ['scaled_by']\n",
    "in var. This is good in case the data is later appended into one anndata object.\n",
    "But my return from the perturb_counts loop (cell below this) is a dictionary of all of the perturb_counts, since appending along any axis will probably either overwrite\n",
    "obs or var.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def perturb_counts(tf_list, scalar, adata): \n",
    "    \"\"\"\n",
    "    Applies a perturbation to the expression data of specific genes in an AnnData object.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Computes the maximum gene expression level for each cell.\n",
    "    2. Applies a scaling operation to the expression levels of genes listed in `tf_list`.\n",
    "       - Each entry of these genes in the matrix is multiplied by the maximum expression level \n",
    "         of its respective cell and a specified scalar value.\n",
    "    3. Updates the AnnData object with new columns:\n",
    "       - 'scaled': A boolean column indicating whether each gene is in the `tf_list`.\n",
    "       - 'scaled_by': Contains the scaling factor used for each gene (the product of the maximum \n",
    "         expression level of each cell and the scalar), or `1` if the gene was not in `tf_list`.\n",
    "    \n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols to be perturbed.\n",
    "    scalar (float): The scalar value used to scale the expression levels.\n",
    "    adata (AnnData): The AnnData object containing gene expression data.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: The updated AnnData object with applied perturbations and new columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute maximum expression level of each cell\n",
    "    med_nonz = np.max(adata.X, axis=1)\n",
    "    \n",
    "    # Create a boolean mask for genes in tf_list\n",
    "    gene_mask = adata.var['gene_symbol'].isin(tf_list)\n",
    "    \n",
    "    # Apply the scaling operation to the specified genes\n",
    "    adata.X[:, gene_mask] *= med_nonz[:, np.newaxis] * scalar\n",
    "    \n",
    "    # Add/Update 'scaled' column in var\n",
    "    adata.var['scaled'] = gene_mask\n",
    "    \n",
    "    # Add/Update 'scaled_by' column in var\n",
    "    adata.var['scaled_by'] = 1  # Default value for genes not in tf_list\n",
    "    adata.var.loc[gene_mask, 'scaled_by'] = med_nonz[:, np.newaxis] * scalar  # Correct scaling factor assignment\n",
    "    \n",
    "    return adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a79c50-3dbb-4d6f-8723-e6f967f41893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "def iterate_perturb_counts(tf_list, scalar_list, adata):\n",
    "    \"\"\"\n",
    "    Applies perturbations to the expression data of specified transcription factors across multiple scalars \n",
    "    and stores the resulting AnnData objects in a dictionary.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Iterates over a list of scalar values.\n",
    "    2. For each scalar, creates a copy of the AnnData object to preserve the original data.\n",
    "    3. Applies the `perturb_counts` function to scale the expression data of genes listed in `tf_list` by\n",
    "       the maximum gene expression of each cell and the current scalar.\n",
    "    4. Stores the perturbed AnnData object in a dictionary with the scalar as the key.\n",
    "\n",
    "    Parameters:\n",
    "    tf_list (list): A list of gene symbols (transcription factors) to be perturbed.\n",
    "    scalar_list (list): A list of scalar values for scaling the gene expression.\n",
    "    adata (AnnData): The AnnData object containing gene expression data (cells x genes).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are scalar values and values are the corresponding perturbed AnnData objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_dict = {}\n",
    "    \n",
    "    for scalar in scalar_list:\n",
    "        # Create a copy of the AnnData object for each scalar value\n",
    "        adata_temp = adata.copy()\n",
    "        \n",
    "        # Apply perturb_counts to the copied AnnData object\n",
    "        perturbed_adata = perturb_counts(tf_list, scalar, adata_temp)\n",
    "        \n",
    "        # Store the perturbed AnnData object in the dictionary with scalar as the key\n",
    "        adata_dict[scalar] = perturbed_adata\n",
    "    \n",
    "    return adata_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f0a9c-18e0-4d3a-8efd-7993accb1048",
   "metadata": {},
   "source": [
    "## Visualize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8542f13-3c5c-4130-9766-0d0a9ce55e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6474b05-224f-4677-902e-5b4962a4bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/nfs/turbo/umms-indikar/shared/projects/DGC/data/tabula_sapiens/extract/\"\n",
    "FILE = \"TS_epithelial.h5ad\"\n",
    "\n",
    "adata = sp.read_h5ad(os.path.join(DATAPATH, FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a5de2-be21-489c-8184-b90f010b06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010c3f2-3294-4f18-bcad-8a9b3abf9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f83ed-4955-4962-a629-f003027303e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.max(axis=1) # what is the value of the highest expressed gene for each cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210614f-0e87-4a8a-b1c5-1cc95c7380ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = 'DDX11L1'\n",
    "index = np.where(adata.var['gene_symbol'] == TF)[0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3d5ad-f2f0-446d-83f3-c63179d369c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['gene_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45904679-08f7-4ec7-b746-4017140120c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa3850-58e1-41b4-9b2a-60db4bea28b1",
   "metadata": {},
   "source": [
    "## Build driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563c2da-5366-4738-a33b-2bfe1e881eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def main(job_number, parameter_file):\n",
    "    \"\"\"\n",
    "    This is the main function for the array job to perform the reprogramming experiment. job_number is a single parameter\n",
    "    that will be used to look up in a parameter table which model, reprogramming recipe, and other information relevant\n",
    "    to the test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine embedding parameters and recipie\n",
    "    df_embedding_parameters = pd.read_csv(parameter_file)\n",
    "    TFs    = df_embedding_parameters['TFs'].values[job_number]\n",
    "    model  = df_embedding_parameters['model'].values[job_number]\n",
    "    source = df_embedding_parameters['source'].values[job_number]\n",
    "    target = df_embedding_parameters['target'].values[job_number]\n",
    "\n",
    "    # Load the source data\n",
    "    adata = \n",
    "\n",
    "    # Perturb the data\n",
    "    perturbed_adata = perturbation_model(adata, TFs)\n",
    "\n",
    "    # Generate embeddings\n",
    "    if model == 'geneformer':\n",
    "        adata_embedded = embed_geneformer([source_adata, perturbed_adata, target_adata])\n",
    "    elif model == 'tGPT':\n",
    "        adata_embedded = embed_tGPT([source_adata, perturbed_adata, target_adata])\n",
    "    elif model == 'scGTP':\n",
    "        adata_embedded = embed_scGTP([source_adata, perturbed_adata, target_adata])\n",
    "\n",
    "    # Save the results to a file\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f3c98-3474-4971-a559-f0a294dba782",
   "metadata": {},
   "source": [
    "## Build parameter dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f04aa-ab4c-44fc-86e0-f69d7f21451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_parameters = {\n",
    "    'source': [],\n",
    "    'target': [],\n",
    "    'TFs'   : [],\n",
    "    'model' : []\n",
    "}\n",
    "models = ['geneformer', 'tGPT', 'scGTP']\n",
    "\n",
    "df = pd.read_csv('data/first_5_recepies_8_29_2024.csv')\n",
    "\n",
    "for i in range(5):\n",
    "    TFs = df['TFs'].values[i].split()\n",
    "    source = df['Source'].values[i]\n",
    "    target = df['Target'].values[i]\n",
    "    for model in models:\n",
    "        embedding_parameters['TFs'].append(TFs)\n",
    "        embedding_parameters['source'].append(source)\n",
    "        embedding_parameters['target'].append(source)\n",
    "        embedding_parameters['model'].append(model)\n",
    "\n",
    "df_embedding_parameters = pd.DataFrame(embedding_parameters)\n",
    "\n",
    "df_embedding_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad22cdb-f1ac-48b6-8053-b69d91309c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02020-7129-4182-9bef-6535490e26a9",
   "metadata": {},
   "source": [
    "# Day 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18574c-9e46-4c1d-9b77-b4f888ae0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a5d48-99dc-4880-809d-519448cbfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known reprogramming regiems\n",
    "df = pd.read_csv('data/known-regiems-T1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457114f-57d5-45e9-ad8d-ecaa06a76d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique transcription factors\n",
    "TFs = []\n",
    "for regime in df['TFs'].unique():\n",
    "    TFs += regime.replace(',', '').split()\n",
    "TFs = list(set(TFs))\n",
    "print(f\"{len(TFs)=}\")\n",
    "TFs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
