{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd54ffda-c843-4725-9412-4e1f6e51d1db",
   "metadata": {},
   "source": [
    "# scFoundation a minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b859421e-4e8d-4d05-8c68-383350ea4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "Tesla V100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "torch.cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af7c5b4-644c-4e33-9f14-29100a3faf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "sys.path.append('/home/jpic/scFoundationProject/scFoundation/scFoundation/model')\n",
    "from pretrainmodels import select_model\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ece07f-d8b6-4ed7-8c3b-eca9a72c128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)  # numpy random generator\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "\n",
    "def convertconfig(ckpt):\n",
    "    newconfig = {}\n",
    "    newconfig['config']={}\n",
    "    model_type = ckpt['config']['model']\n",
    "    \n",
    "    for key, val in ckpt['config']['model_config'][model_type].items():\n",
    "        newconfig['config'][key]=val\n",
    "        \n",
    "    for key, val in ckpt['config']['dataset_config']['rnaseq'].items():\n",
    "        newconfig['config'][key]=val\n",
    "        \n",
    "    if model_type == 'performergau_resolution':\n",
    "        model_type = 'performer_gau'\n",
    "    \n",
    "    import collections\n",
    "    d = collections.OrderedDict()\n",
    "    for key, val in ckpt['state_dict'].items():\n",
    "        d[str(key).split('model.')[1]]=val\n",
    "        \n",
    "    newconfig['config']['model_type']=model_type\n",
    "    newconfig['model_state_dict']=d\n",
    "    newconfig['config']['pos_embed']=False\n",
    "    newconfig['config']['device']='cuda'\n",
    "    return newconfig\n",
    "\n",
    "def loaddata(data_path, verbose=True, pre_normalized='T', input_type='singlecell', demo=False):\n",
    "    #Load data\n",
    "    if data_path[-3:]=='npz':\n",
    "        gexpr_feature = scipy.sparse.load_npz(data_path)\n",
    "        gexpr_feature = pd.DataFrame(gexpr_feature.toarray())\n",
    "    elif data_path[-4:]=='h5ad':\n",
    "        gexpr_feature = sc.read_h5ad(data_path)\n",
    "        idx = gexpr_feature.obs_names.tolist()\n",
    "        col = gexpr_feature.var.gene_name.tolist()\n",
    "        if issparse(gexpr_feature.X):\n",
    "            gexpr_feature = gexpr_feature.X.toarray()\n",
    "        else:\n",
    "            gexpr_feature = gexpr_feature\n",
    "        gexpr_feature = pd.DataFrame(gexpr_feature,index=idx,columns=col)\n",
    "    elif data_path[-3:]=='npy':\n",
    "        gexpr_feature = np.load(data_path)\n",
    "        gexpr_feature = pd.DataFrame(gexpr_feature)\n",
    "    else:\n",
    "        gexpr_feature=pd.read_csv(data_path,index_col=0)\n",
    "    \n",
    "    if gexpr_feature.shape[1]<19264:\n",
    "        print('covert gene feature into 19264')\n",
    "        gexpr_feature, to_fill_columns,var = main_gene_selection(gexpr_feature,gene_list)\n",
    "        assert gexpr_feature.shape[1]>=19264\n",
    "    \n",
    "    if (pre_normalized == 'F') and (input_type == 'bulk'):\n",
    "        adata = sc.AnnData(gexpr_feature)\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "        gexpr_feature = pd.DataFrame(adata.X,index=adata.obs_names,columns=adata.var_names)\n",
    "\n",
    "    if demo:\n",
    "        gexpr_feature = gexpr_feature.iloc[:10,:]\n",
    "    if verbose:\n",
    "        print(f'data.shape={gexpr_feature.shape}')\n",
    "    return gexpr_feature\n",
    "\n",
    "def main_gene_selection(X_df, gene_list):\n",
    "    \"\"\"\n",
    "    Describe:\n",
    "        rebuild the input adata to select target genes encode protein \n",
    "    Parameters:\n",
    "        adata->`~anndata.AnnData` object: adata with var index_name by gene symbol\n",
    "        gene_list->list: wanted target gene \n",
    "    Returns:\n",
    "        adata_new->`~anndata.AnnData` object\n",
    "        to_fill_columns->list: zero padding gene\n",
    "    \"\"\"\n",
    "    to_fill_columns = list(set(gene_list) - set(X_df.columns))\n",
    "    padding_df = pd.DataFrame(np.zeros((X_df.shape[0], len(to_fill_columns))), \n",
    "                              columns=to_fill_columns, \n",
    "                              index=X_df.index)\n",
    "    X_df = pd.DataFrame(np.concatenate([df.values for df in [X_df, padding_df]], axis=1), \n",
    "                        index=X_df.index, \n",
    "                        columns=list(X_df.columns) + list(padding_df.columns))\n",
    "    X_df = X_df[gene_list]\n",
    "    \n",
    "    var = pd.DataFrame(index=X_df.columns)\n",
    "    var['mask'] = [1 if i in to_fill_columns else 0 for i in list(var.index)]\n",
    "    return X_df, to_fill_columns,var\n",
    "\n",
    "def gatherData(data, labels, pad_token_id):\n",
    "    \"\"\"\n",
    "    Gathers data and prepares it for model input by handling padding and sorting based on labels.\n",
    "\n",
    "    Parameters:\n",
    "    data (torch.Tensor): The input data tensor.\n",
    "    labels (torch.Tensor): The labels tensor indicating the presence of values in the data tensor.\n",
    "    pad_token_id (int): The token ID used for padding.\n",
    "\n",
    "    Returns:\n",
    "    new_data (torch.Tensor): The gathered data tensor with padding handled.\n",
    "    padding_labels (torch.Tensor): The tensor indicating which positions are padding.\n",
    "    \"\"\"\n",
    "    # Calculate the number of values per row\n",
    "    value_nums = labels.sum(1)\n",
    "    max_num = max(value_nums)\n",
    "\n",
    "    # Create fake data for padding\n",
    "    fake_data = torch.full((data.shape[0], max_num), pad_token_id, device=data.device)\n",
    "    data = torch.hstack([data, fake_data])\n",
    "\n",
    "    # Create fake labels for padding\n",
    "    fake_label = torch.full((labels.shape[0], max_num), 1, device=labels.device)\n",
    "    none_labels = ~labels\n",
    "    labels = labels.float()\n",
    "    labels[none_labels] = torch.tensor(-float('Inf'), device=labels.device)\n",
    "\n",
    "    # Create a tensor to adjust labels for sorting\n",
    "    tmp_data = torch.tensor([(i + 1) * 20000 for i in range(labels.shape[1], 0, -1)], device=labels.device)\n",
    "    labels += tmp_data\n",
    "\n",
    "    # Concatenate the original labels with fake labels\n",
    "    labels = torch.hstack([labels, fake_label])\n",
    "\n",
    "    # Sort and gather data based on the top-k labels\n",
    "    fake_label_gene_idx = labels.topk(max_num).indices\n",
    "    new_data = torch.gather(data, 1, fake_label_gene_idx)\n",
    "\n",
    "    # Determine which positions are padding\n",
    "    padding_labels = (new_data == pad_token_id)\n",
    "\n",
    "    return new_data, padding_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefd023-9542-4e5b-be4c-75631692697a",
   "metadata": {},
   "source": [
    "**Code to preformat the data**\n",
    "\n",
    "```python\n",
    "    # X_df represents your single cell data with cells in rows and genes in columns\n",
    "    gene_list_df = pd.read_csv('/home/jpic/scFoundationProject/scFoundation/scFoundation/OS_scRNA_gene_index.19264.tsv', header=0, delimiter='\\t')\n",
    "    gene_list = list(gene_list_df['gene_name'])\n",
    "    X_df, to_fill_columns, var = main_gene_selection(X_df, gene_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c3c839-aff5-49ba-97cc-d168bbe3b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(10, 19264)\n"
     ]
    }
   ],
   "source": [
    "DATAPATH = '/nfs/turbo/umms-indikar/shared/projects/foundation_models/example_inputs/scFoundation/cell_type_rawdata/zheng/data_test_count.npy'\n",
    "data = loaddata(DATAPATH, demo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17cd3da-5eb0-42c0-90e4-6d77c28a2275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19254</th>\n",
       "      <th>19255</th>\n",
       "      <th>19256</th>\n",
       "      <th>19257</th>\n",
       "      <th>19258</th>\n",
       "      <th>19259</th>\n",
       "      <th>19260</th>\n",
       "      <th>19261</th>\n",
       "      <th>19262</th>\n",
       "      <th>19263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 19264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   19254  19255  19256  19257  19258  19259  19260  19261  19262  19263  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10 rows x 19264 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50b722b-7f51-48a0-ae11-8a57ab5f71a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ckpt_path = '/nfs/turbo/umms-indikar/shared/projects/foundation_models/scFoundation/scFoundation/model/models/models.ckpt'\n",
    "key = 'cell'\n",
    "\n",
    "model_data = torch.load(best_ckpt_path,map_location='cpu')\n",
    "model_data = model_data[key]\n",
    "model_data = convertconfig(model_data)\n",
    "if not model_data.__contains__('config'):\n",
    "    print('***** No config *****')\n",
    "    config={}\n",
    "    config['model_type']='flash_all'\n",
    "else:\n",
    "    config=model_data['config']\n",
    "    print(config)\n",
    "if not config.__contains__('qv_dim'):\n",
    "    if config['model'] != 'mae_autobin':\n",
    "        if config.__contains__('dim_head'):\n",
    "            config['qv_dim']=config['dim_head']\n",
    "        else:\n",
    "            print('***** No qv_dim ***** set 64')\n",
    "            config['qv_dim']= 64\n",
    "if not config.__contains__('ppi_edge'):\n",
    "    config['ppi_edge']=None\n",
    "model = select_model(config)\n",
    "model_state_dict = model_data['model_state_dict']    \n",
    "model.load_state_dict(model_state_dict)\n",
    "# return model.cuda(),config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be2caa6-dddd-4476-932c-6b7c5fe24b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaeAutobin(\n",
       "  (token_emb): AutoDiscretizationEmbedding2(\n",
       "    (mlp): Linear(in_features=1, out_features=100, bias=True)\n",
       "    (mlp2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "    (Softmax): Softmax(dim=-1)\n",
       "    (emb): Embedding(100, 768)\n",
       "    (emb_mask): Embedding(1, 768)\n",
       "    (emb_pad): Embedding(1, 768)\n",
       "  )\n",
       "  (pos_emb): Embedding(19267, 768)\n",
       "  (decoder_embed): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (to_final): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (encoder): pytorchTransformerModule(\n",
       "    (transformer_encoder): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): PerformerModule(\n",
       "    (performer): Performer(\n",
       "      (net): SequentialSequence(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x ModuleList(\n",
       "            (0): PreLayerNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): SelfAttention(\n",
       "                (fast_attention): FastAttention(\n",
       "                  (kernel_fn): ReLU()\n",
       "                )\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): PreLayerNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Chunk(\n",
       "                (fn): FeedForward(\n",
       "                  (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0289e03e-eaa1-41c1-83e3-a9e19c1e90c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the cell below before this one\n",
    "embed(data, input_type='singlecell', pre_normalized='T', tgthighres='f0.5', output_type='cell', pool_type='all', \n",
    "          pretrainmodel=model, pretrainconfig=config, gatherData=gatherData, getEncoerDecoderData=None, strname='output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c48c04-79d5-40c1-9c1c-3e6949337146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def embed(gexpr_feature, input_type='singlecell', pre_normalized='T', tgthighres='f0.5', output_type='cell', pool_type='all', \n",
    "          pretrainmodel=None, pretrainconfig=None, gatherData=None, getEncoerDecoderData=None, strname='output.npy'):\n",
    "    \"\"\"\n",
    "    Embeds gene expression data using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    gexpr_feature (DataFrame): The gene expression feature data.\n",
    "    input_type (str): Type of input data ('bulk' or 'singlecell'). Default is 'singlecell'.\n",
    "    pre_normalized (str): Indicates if the data is pre-normalized ('T', 'F', 'A'). Default is 'T'.\n",
    "    tgthighres (str): Target high resolution ('f', 'a', 't' followed by a number). Default is 'f0.5'.\n",
    "    output_type (str): Type of output embedding ('cell', 'gene', 'gene_batch', 'gene_expression'). Default is 'cell'.\n",
    "    pool_type (str): Pooling type for embeddings ('all' or 'max'). Default is 'all'.\n",
    "    pretrainmodel (torch.nn.Module): The pre-trained model used for embedding.\n",
    "    pretrainconfig (dict): Configuration dictionary for the pre-trained model.\n",
    "    gatherData (function): Function to gather data for the model.\n",
    "    getEncoerDecoderData (function): Function to get encoder-decoder data.\n",
    "    strname (str): The name of the output file to save embeddings. Default is 'output.npy'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    geneexpemb = []\n",
    "    batchcontainer = []\n",
    "\n",
    "    for i in tqdm(range(gexpr_feature.shape[0])):\n",
    "        with torch.no_grad():\n",
    "            if input_type == 'bulk':\n",
    "                if pre_normalized == 'T':\n",
    "                    totalcount = gexpr_feature.iloc[i, :].sum()\n",
    "                elif pre_normalized == 'F':\n",
    "                    totalcount = np.log10(gexpr_feature.iloc[i, :].sum())\n",
    "                else:\n",
    "                    raise ValueError('pre_normalized must be T or F')\n",
    "                tmpdata         = gexpr_feature.iloc[i, :].tolist()\n",
    "                pretrain_gene_x = torch.tensor(tmpdata + [totalcount, totalcount]).unsqueeze(0).cuda()\n",
    "                data_gene_ids   = torch.arange(19266, device=pretrain_gene_x.device).repeat(pretrain_gene_x.shape[0], 1)\n",
    "            \n",
    "            elif input_type == 'singlecell':\n",
    "                if pre_normalized == 'F':\n",
    "                    tmpdata = np.log1p(gexpr_feature.iloc[i, :] / gexpr_feature.iloc[i, :].sum() * 1e4).tolist()\n",
    "                elif pre_normalized == 'T':\n",
    "                    tmpdata = gexpr_feature.iloc[i, :].tolist()\n",
    "                elif pre_normalized == 'A':\n",
    "                    tmpdata = gexpr_feature.iloc[i, :-1].tolist()\n",
    "                else:\n",
    "                    raise ValueError('pre_normalized must be T, F, or A')\n",
    "\n",
    "                if pre_normalized == 'A':\n",
    "                    totalcount = gexpr_feature.iloc[i, -1]\n",
    "                else:\n",
    "                    totalcount = gexpr_feature.iloc[i, :].sum()\n",
    "\n",
    "                if tgthighres[0] == 'f':\n",
    "                    pretrain_gene_x = torch.tensor(tmpdata + [np.log10(totalcount * float(tgthighres[1:])), np.log10(totalcount)]).unsqueeze(0).cuda()\n",
    "                elif tgthighres[0] == 'a':\n",
    "                    pretrain_gene_x = torch.tensor(tmpdata + [np.log10(totalcount) + float(tgthighres[1:]), np.log10(totalcount)]).unsqueeze(0).cuda()\n",
    "                elif tgthighres[0] == 't':\n",
    "                    pretrain_gene_x = torch.tensor(tmpdata + [float(tgthighres[1:]), np.log10(totalcount)]).unsqueeze(0).cuda()\n",
    "                else:\n",
    "                    raise ValueError('tgthighres must start with f, a, or t')\n",
    "                data_gene_ids = torch.arange(19266, device=pretrain_gene_x.device).repeat(pretrain_gene_x.shape[0], 1)\n",
    "\n",
    "            value_labels = pretrain_gene_x > 0\n",
    "            x, x_padding = gatherData(pretrain_gene_x, value_labels, pretrainconfig['pad_token_id'])\n",
    "\n",
    "            if output_type == 'cell':\n",
    "                position_gene_ids, _ = gatherData(data_gene_ids, value_labels, pretrainconfig['pad_token_id'])\n",
    "                x = pretrainmodel.token_emb(torch.unsqueeze(x, 2).float(), output_weight=0)\n",
    "                position_emb = pretrainmodel.pos_emb(position_gene_ids)\n",
    "                x += position_emb\n",
    "                geneemb = pretrainmodel.encoder(x, x_padding)\n",
    "\n",
    "                geneemb1 = geneemb[:, -1, :]\n",
    "                geneemb2 = geneemb[:, -2, :]\n",
    "                geneemb3, _ = torch.max(geneemb[:, :-2, :], dim=1)\n",
    "                geneemb4 = torch.mean(geneemb[:, :-2, :], dim=1)\n",
    "                if pool_type == 'all':\n",
    "                    geneembmerge = torch.concat([geneemb1, geneemb2, geneemb3, geneemb4], axis=1)\n",
    "                elif pool_type == 'max':\n",
    "                    geneembmerge, _ = torch.max(geneemb, dim=1)\n",
    "                else:\n",
    "                    raise ValueError('pool_type must be all or max')\n",
    "                geneexpemb.append(geneembmerge.detach().cpu().numpy())\n",
    "\n",
    "            elif output_type == 'gene':\n",
    "                pretrainmodel.to_final = None\n",
    "                encoder_data, encoder_position_gene_ids, encoder_data_padding, encoder_labels, decoder_data, decoder_data_padding, new_data_raw, data_mask_labels, decoder_position_gene_ids = getEncoerDecoderData(pretrain_gene_x.float(), pretrain_gene_x.float(), pretrainconfig)\n",
    "                out = pretrainmodel.forward(x=encoder_data, padding_label=encoder_data_padding,\n",
    "                                            encoder_position_gene_ids=encoder_position_gene_ids,\n",
    "                                            encoder_labels=encoder_labels,\n",
    "                                            decoder_data=decoder_data,\n",
    "                                            mask_gene_name=False,\n",
    "                                            mask_labels=None,\n",
    "                                            decoder_position_gene_ids=decoder_position_gene_ids,\n",
    "                                            decoder_data_padding_labels=decoder_data_padding)\n",
    "                out = out[:, :19264, :].contiguous()\n",
    "                geneexpemb.append(out.detach().cpu().numpy())\n",
    "\n",
    "            elif output_type == 'gene_batch':\n",
    "                batchcontainer.append(pretrain_gene_x.float())\n",
    "                if len(batchcontainer) == gexpr_feature.shape[0]:\n",
    "                    batchcontainer = torch.concat(batchcontainer, axis=0)\n",
    "                else:\n",
    "                    continue\n",
    "                pretrainmodel.to_final = None\n",
    "                encoder_data, encoder_position_gene_ids, encoder_data_padding, encoder_labels, decoder_data, decoder_data_padding, new_data_raw, data_mask_labels, decoder_position_gene_ids = getEncoerDecoderData(batchcontainer, batchcontainer, pretrainconfig)\n",
    "                out = pretrainmodel.forward(x=encoder_data, padding_label=encoder_data_padding,\n",
    "                                            encoder_position_gene_ids=encoder_position_gene_ids,\n",
    "                                            encoder_labels=encoder_labels,\n",
    "                                            decoder_data=decoder_data,\n",
    "                                            mask_gene_name=False,\n",
    "                                            mask_labels=None,\n",
    "                                            decoder_position_gene_ids=decoder_position_gene_ids,\n",
    "                                            decoder_data_padding_labels=decoder_data_padding)\n",
    "                geneexpemb = out[:, :19264, :].contiguous().detach().cpu().numpy()\n",
    "\n",
    "            elif output_type == 'gene_expression':\n",
    "                encoder_data, encoder_position_gene_ids, encoder_data_padding, encoder_labels, decoder_data, decoder_data_padding, new_data_raw, data_mask_labels, decoder_position_gene_ids = getEncoerDecoderData(pretrain_gene_x.float(), pretrain_gene_x.float(), pretrainconfig)\n",
    "                out = pretrainmodel.forward(x=encoder_data, padding_label=encoder_data_padding,\n",
    "                                            encoder_position_gene_ids=encoder_position_gene_ids,\n",
    "                                            encoder_labels=encoder_labels,\n",
    "                                            decoder_data=decoder_data,\n",
    "                                            mask_gene_name=False,\n",
    "                                            mask_labels=None,\n",
    "                                            decoder_position_gene_ids=decoder_position_gene_ids,\n",
    "                                            decoder_data_padding_labels=decoder_data_padding)\n",
    "                out = out[:, :19264].contiguous()\n",
    "                geneexpemb.append(out.detach().cpu().numpy())                \n",
    "            else:\n",
    "                raise ValueError('output_type must be cell, gene, gene_batch, or gene_expression')\n",
    "\n",
    "    geneexpemb = np.squeeze(np.array(geneexpemb))\n",
    "    print(geneexpemb.shape)\n",
    "    np.save(strname, geneexpemb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915eefde-b7d9-4e27-9fd0-18a90b9481e7",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954dfe09-7c82-4292-a525-7905f963bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import einops\n",
    "import scanpy as sc\n",
    "import local_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93753f83-3c6d-44d1-aab4-47114c7cea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/jpic/scFoundationProject/scFoundation/scFoundation/model')\n",
    "from load import load_model_frommmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d1ea7c-83bc-42de-a4ba-a046a2e97324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_gene_selection(X_df, gene_list):\n",
    "    \"\"\"\n",
    "    Describe:\n",
    "        rebuild the input adata to select target genes encode protein \n",
    "    Parameters:\n",
    "        adata->`~anndata.AnnData` object: adata with var index_name by gene symbol\n",
    "        gene_list->list: wanted target gene \n",
    "    Returns:\n",
    "        adata_new->`~anndata.AnnData` object\n",
    "        to_fill_columns->list: zero padding gene\n",
    "    \"\"\"\n",
    "    to_fill_columns = list(set(gene_list) - set(X_df.columns))\n",
    "    padding_df = pd.DataFrame(np.zeros((X_df.shape[0], len(to_fill_columns))), \n",
    "                              columns=to_fill_columns, \n",
    "                              index=X_df.index)\n",
    "    X_df = pd.DataFrame(np.concatenate([df.values for df in [X_df, padding_df]], axis=1), \n",
    "                        index=X_df.index, \n",
    "                        columns=list(X_df.columns) + list(padding_df.columns))\n",
    "    X_df = X_df[gene_list]\n",
    "    \n",
    "    var = pd.DataFrame(index=X_df.columns)\n",
    "    var['mask'] = [1 if i in to_fill_columns else 0 for i in list(var.index)]\n",
    "    return X_df, to_fill_columns,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af89016-c12a-4085-8713-e5f852dda148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 68450 × 16906\n",
       "    obs: 'TSNE.1', 'TSNE.2', 'celltype', 'n_genes'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/nfs/turbo/umms-indikar/shared/projects/foundation_models/example_inputs/scBERT/Zheng68K.h5ad'\n",
    "adata     = sc.read_h5ad(data_path)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2099210a-dc6b-4289-b100-34931e0fa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame.sparse.from_spmatrix(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ede6916-4178-494c-83f4-aae9f63fc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac2130c-7d7b-4476-b850-c5a65da51fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 16906 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcelltype\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mX_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(adata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      3\u001b[0m X_df\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 16906 elements"
     ]
    }
   ],
   "source": [
    "X_df.index = adata.obs['celltype']\n",
    "X_df.columns = list(adata.var.index)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b582c-7b5d-4034-831e-33544c4780bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9a9d50e-7755-4b3d-a198-8c0409d630b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_df = pd.read_csv('/home/jpic/scFoundationProject/scFoundation/scFoundation/OS_scRNA_gene_index.19264.tsv', header=0, delimiter='\\t')\n",
    "gene_list = list(gene_list_df['gene_name'])\n",
    "X_df, to_fill_columns, var = main_gene_selection(X_df, gene_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7cecbcd-186b-4526-b20d-bd66dd2b802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CD8+ Cytotoxic T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+/CD45RA+ Naive Cytotoxic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD4+/CD45RO+ Memory</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD19+ B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD4+/CD25 T Reg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+ Cytotoxic T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.241876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+/CD45RA+ Naive Cytotoxic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+ Cytotoxic T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+ Cytotoxic T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8+ Cytotoxic T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68450 rows × 19264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              A1BG  A1CF  A2M  A2ML1  A3GALT2  A4GALT  A4GNT  \\\n",
       "celltype                                                                       \n",
       "CD8+ Cytotoxic T               0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD4+/CD45RO+ Memory            0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD19+ B                        0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD4+/CD25 T Reg                0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "...                            ...   ...  ...    ...      ...     ...    ...   \n",
       "CD8+ Cytotoxic T               0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD8+ Cytotoxic T               0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD8+ Cytotoxic T               0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "CD8+ Cytotoxic T               0.0   0.0  0.0    0.0      0.0     0.0    0.0   \n",
       "\n",
       "                              AAAS      AACS  AADAC  ...  ZWILCH  ZWINT  ZXDA  \\\n",
       "celltype                                             ...                        \n",
       "CD8+ Cytotoxic T               0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD4+/CD45RO+ Memory            0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD19+ B                        0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD4+/CD25 T Reg                0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "...                            ...       ...    ...  ...     ...    ...   ...   \n",
       "CD8+ Cytotoxic T               0.0  3.241876    0.0  ...     0.0    0.0   0.0   \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD8+ Cytotoxic T               0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD8+ Cytotoxic T               0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "CD8+ Cytotoxic T               0.0  0.000000    0.0  ...     0.0    0.0   0.0   \n",
       "\n",
       "                              ZXDB  ZXDC  ZYG11A  ZYG11B  ZYX  ZZEF1  ZZZ3  \n",
       "celltype                                                                    \n",
       "CD8+ Cytotoxic T               0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD4+/CD45RO+ Memory            0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD19+ B                        0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD4+/CD25 T Reg                0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "...                            ...   ...     ...     ...  ...    ...   ...  \n",
       "CD8+ Cytotoxic T               0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD8+/CD45RA+ Naive Cytotoxic   0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD8+ Cytotoxic T               0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD8+ Cytotoxic T               0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "CD8+ Cytotoxic T               0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "\n",
       "[68450 rows x 19264 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5feb0a5c-818a-427f-b341-d9b4c270d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "Tesla V100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d596ce7-9f56-49b2-803e-b3685d84077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "sys.path.append('/home/jpic/scFoundationProject/scFoundation/scFoundation/model')\n",
    "from pretrainmodels import select_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8e28a3-2c0a-4258-a8f7-9984280151cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertconfig(ckpt):\n",
    "    newconfig = {}\n",
    "    newconfig['config']={}\n",
    "    model_type = ckpt['config']['model']\n",
    "    \n",
    "    for key, val in ckpt['config']['model_config'][model_type].items():\n",
    "        newconfig['config'][key]=val\n",
    "        \n",
    "    for key, val in ckpt['config']['dataset_config']['rnaseq'].items():\n",
    "        newconfig['config'][key]=val\n",
    "        \n",
    "    if model_type == 'performergau_resolution':\n",
    "        model_type = 'performer_gau'\n",
    "    \n",
    "    import collections\n",
    "    d = collections.OrderedDict()\n",
    "    for key, val in ckpt['state_dict'].items():\n",
    "        d[str(key).split('model.')[1]]=val\n",
    "        \n",
    "    newconfig['config']['model_type']=model_type\n",
    "    newconfig['model_state_dict']=d\n",
    "    newconfig['config']['pos_embed']=False\n",
    "    newconfig['config']['device']='cuda'\n",
    "    return newconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8783644-c41c-433a-b79a-f5a2c81b5a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ckpt_path = '/nfs/turbo/umms-indikar/shared/projects/foundation_models/scFoundation/scFoundation/model/models/models.ckpt'\n",
    "key = 'cell'\n",
    "\n",
    "model_data = torch.load(best_ckpt_path,map_location='cpu')\n",
    "model_data = model_data[key]\n",
    "model_data = convertconfig(model_data)\n",
    "if not model_data.__contains__('config'):\n",
    "    print('***** No config *****')\n",
    "    config={}\n",
    "    config['model_type']='flash_all'\n",
    "else:\n",
    "    config=model_data['config']\n",
    "    print(config)\n",
    "if not config.__contains__('qv_dim'):\n",
    "    if config['model'] != 'mae_autobin':\n",
    "        if config.__contains__('dim_head'):\n",
    "            config['qv_dim']=config['dim_head']\n",
    "        else:\n",
    "            print('***** No qv_dim ***** set 64')\n",
    "            config['qv_dim']= 64\n",
    "if not config.__contains__('ppi_edge'):\n",
    "    config['ppi_edge']=None\n",
    "model = select_model(config)\n",
    "model_state_dict = model_data['model_state_dict']    \n",
    "model.load_state_dict(model_state_dict)\n",
    "# return model.cuda(),config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3229dcd-75cf-4ce0-9d47-b412863ae7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pretrainmodels.mae_autobin.MaeAutobin"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c078b45-ee74-4540-8458-193d27f9539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m----> 2\u001b[0m pretrainmodel, pretrainconfig \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_frommmf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/nfs/turbo/umms-indikar/shared/projects/foundation_models/scFoundation/scFoundation/model/models/models.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scFoundationProject/scFoundation/scFoundation/model/load.py:147\u001b[0m, in \u001b[0;36mload_model_frommmf\u001b[0;34m(best_ckpt_path, key)\u001b[0m\n\u001b[1;32m    145\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]    \n\u001b[1;32m    146\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,config\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "pretrainmodel, pretrainconfig = load_model_frommmf('/nfs/turbo/umms-indikar/shared/projects/foundation_models/scFoundation/scFoundation/model/models/models.ckpt','cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e06fd3-f9ab-4c69-a669-5b364aac4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ed8b657-2e98-422d-a5b6-a888da0dee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
